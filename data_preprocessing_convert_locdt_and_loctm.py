# -*- coding: utf-8 -*-
"""data_preprocessing convert locdt and loctm

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12v9CqDjq5Ge1vYWGv7Pv3QqUHhiZxnMp

# Load data
"""

# 如果有使用 coloab 再執行此 cell
from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np

with open('/content/drive/My Drive/fintech-introduction/term-project/train.csv', 'r') as f:
  df = pd.read_csv(f).set_index('txkey')
df

# with open('/content/drive/My Drive/fintech-introduction/term-project/test.csv', 'r') as f:
#   df_test = pd.read_csv(f).set_index('txkey')
# df_test

"""### txkey's order is not align with locdt's order"""

# df_sort = df.sort_index().values
# for i in range(len(df_sort)):
#   print(df_sort[i][14])

# df_test.sort_index()

"""### fill the nan data as 'NA'"""

df = df.fillna('NA')
df

"""### convert 'N'->0, 'Y'->1, 'NA'->2"""

df.ecfg = df.ecfg.map(dict(Y=1, N=0, NA=2))
df.flbmk = df.flbmk.map(dict(Y=1, N=0, NA=2))
df.flg_3dsmk = df.flg_3dsmk.map(dict(Y=1, N=0, NA=2))
df.insfg = df.insfg.map(dict(Y=1, N=0, NA=2))
df.ovrlt = df.ovrlt.map(dict(Y=1, N=0, NA=2))
df

df = df.sort_values('locdt')
df

# df_test = df_test.fillna('NA')
# df_test

df.to_csv("/content/drive/My Drive/fintech-introduction/term-project/train_sorted_strConverted_fillNA.csv")

"""# Data Preprocessing

### convert locdt to range [0,6] to meet the weekdays
"""

df['locdt'] = df['locdt'] % 7
df

# df_test['locdt'] = df_test['locdt'] % 7
# df_test

"""### convert loctm to range HH[0:23], MM[0:59], SS[0:59]"""

try:
  df['hh'] = (df['loctm'] / 10000).astype(int)
  df['mm'] = ((df['loctm'] % 10000) / 100).astype(int)
  df['ss'] = (df['loctm'] % 100).astype(int)
except:
  print('already convert!')

df = df.drop(['loctm'], axis=1)
df

# try:
#   df_test['hh'] = (df_test['loctm'] / 10000).astype(int)
#   df_test['mm'] = ((df_test['loctm'] % 10000) / 100).astype(int)
#   df_test['ss'] = (df_test['loctm'] % 100).astype(int)
# except:
#   print('already convert!')

# df_test = df_test.drop(['loctm'], axis=1)
# df_test

"""### save the converted dataset"""

df.to_csv("/content/drive/My Drive/fintech-introduction/term-project/train_locdt_loctm_converted.csv")

# df_test.to_csv("/content/drive/My Drive/fintech-introduction/term-project/test_convert_locdt_loctm.csv")

"""### 數值型"""

# from sklearn.preprocessing import StandardScaler
# scaler = StandardScaler()
# X_cont = scaler.fit_transform(df_cont)
# X_cont.shape, type(X_cont)

# df_cont.describe()

"""### 類別型"""

# df_disc = df[col_names_disc].copy()
# df_disc.head()

# from sklearn.preprocessing import LabelEncoder
# les = {}
# for c in col_names_disc:
#     le = LabelEncoder()
#     df_disc.loc[:,c] = le.fit_transform(df_disc.loc[:,c])
#     les.update({c:le})
# df_disc.head()

# from sklearn.preprocessing import OneHotEncoder
# ohe = OneHotEncoder(sparse=False)
# X_disc = ohe.fit_transform(df_disc)
# # cut_point = ohe.feature_indices_
# # print("feature cut point: ", cut_point)
# X_disc.shape, type(X_disc)

# new_col_names_disc = []
# for c in col_names_disc: 
#     le = les[c]
#     new_col_names_disc += [ c+'_'+str(cl) for cl in le.classes_ ]
# assert len(new_col_names_disc) == X_disc.shape[1]

# df_disc = pd.DataFrame(data=X_disc, index=df.index, columns=new_col_names_disc)
# df_disc.head()

"""### save the converted feature"""

# df = pd.concat((df_cont, df_disc), 1)
# df.shape

# df = pd.concat((df, y_train), 1)
# df.shape

# df = df.sample(frac=0.5)

# df['flbmk']

# df.to_csv("/content/drive/My Drive/fintech-introduction/term-project/train_X_preprocess_less.csv")

# y_train.to_csv("/content/drive/My Drive/fintech-introduction/term-project/train_Y.csv")