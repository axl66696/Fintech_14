{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simpleNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPnU2cmtpgAD",
        "outputId": "dfe5a841-0c4f-4ed2-85a2-1c0c998a0f84"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMgfRu-gdwfD"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score, confusion_matrix, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score , average_precision_score \n",
        "from sklearn.metrics import f1_score, confusion_matrix, precision_recall_curve, roc_curve ,auc , log_loss ,  classification_report \n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODv0Tkpzdy0-"
      },
      "source": [
        "# Data Processing scenario 1\n",
        "- fill null data and convert str to int\n",
        "- 64%(0.8 * 0.8) data to train\n",
        "- 16%(0.8 * 0.2) to validate\n",
        "- 20% to test\n",
        "- f1 : 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "-3b4bU9Td1_c",
        "outputId": "f50e0219-e015-4c7a-c1d0-7de22ecf585e"
      },
      "source": [
        "import pandas as pd\n",
        "with open('/content/drive/My Drive/fintech-introduction/term-project/train_sorted_strConverted_fillNA.csv', 'r') as f:\n",
        "  df = pd.read_csv(f)\n",
        "  # df = df.set_index('txkey')\n",
        "\n",
        "\n",
        "# print(df_X)\n",
        "# print(df_y)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>txkey</th>\n",
              "      <th>acqic</th>\n",
              "      <th>bacno</th>\n",
              "      <th>cano</th>\n",
              "      <th>conam</th>\n",
              "      <th>contp</th>\n",
              "      <th>csmcu</th>\n",
              "      <th>ecfg</th>\n",
              "      <th>etymd</th>\n",
              "      <th>flbmk</th>\n",
              "      <th>flg_3dsmk</th>\n",
              "      <th>fraud_ind</th>\n",
              "      <th>hcefg</th>\n",
              "      <th>insfg</th>\n",
              "      <th>iterm</th>\n",
              "      <th>locdt</th>\n",
              "      <th>loctm</th>\n",
              "      <th>mcc</th>\n",
              "      <th>mchno</th>\n",
              "      <th>ovrlt</th>\n",
              "      <th>scity</th>\n",
              "      <th>stocn</th>\n",
              "      <th>stscd</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1547337</td>\n",
              "      <td>6767</td>\n",
              "      <td>137279</td>\n",
              "      <td>176279</td>\n",
              "      <td>785.96</td>\n",
              "      <td>5</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>70602.0</td>\n",
              "      <td>191</td>\n",
              "      <td>16615</td>\n",
              "      <td>0</td>\n",
              "      <td>5817</td>\n",
              "      <td>102</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>361558</td>\n",
              "      <td>6032</td>\n",
              "      <td>95126</td>\n",
              "      <td>90258</td>\n",
              "      <td>325.94</td>\n",
              "      <td>5</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>192920.0</td>\n",
              "      <td>251</td>\n",
              "      <td>78641</td>\n",
              "      <td>0</td>\n",
              "      <td>5817</td>\n",
              "      <td>102</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1833662</td>\n",
              "      <td>6215</td>\n",
              "      <td>104992</td>\n",
              "      <td>168046</td>\n",
              "      <td>288.05</td>\n",
              "      <td>5</td>\n",
              "      <td>62</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>160124.0</td>\n",
              "      <td>380</td>\n",
              "      <td>54238</td>\n",
              "      <td>0</td>\n",
              "      <td>6580</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1119486</td>\n",
              "      <td>6717</td>\n",
              "      <td>158233</td>\n",
              "      <td>33494</td>\n",
              "      <td>796.90</td>\n",
              "      <td>5</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>153353.0</td>\n",
              "      <td>304</td>\n",
              "      <td>33656</td>\n",
              "      <td>0</td>\n",
              "      <td>5800</td>\n",
              "      <td>102</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1047761</td>\n",
              "      <td>5975</td>\n",
              "      <td>78764</td>\n",
              "      <td>162106</td>\n",
              "      <td>800.02</td>\n",
              "      <td>5</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>191448.0</td>\n",
              "      <td>263</td>\n",
              "      <td>93792</td>\n",
              "      <td>0</td>\n",
              "      <td>5817</td>\n",
              "      <td>102</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1521782</th>\n",
              "      <td>1927172</td>\n",
              "      <td>6618</td>\n",
              "      <td>65727</td>\n",
              "      <td>181927</td>\n",
              "      <td>228.54</td>\n",
              "      <td>5</td>\n",
              "      <td>62</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>90</td>\n",
              "      <td>165427.0</td>\n",
              "      <td>192</td>\n",
              "      <td>65472</td>\n",
              "      <td>0</td>\n",
              "      <td>6593</td>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1521783</th>\n",
              "      <td>239570</td>\n",
              "      <td>6769</td>\n",
              "      <td>43220</td>\n",
              "      <td>18630</td>\n",
              "      <td>939.74</td>\n",
              "      <td>5</td>\n",
              "      <td>62</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>90</td>\n",
              "      <td>124232.0</td>\n",
              "      <td>373</td>\n",
              "      <td>79200</td>\n",
              "      <td>0</td>\n",
              "      <td>5817</td>\n",
              "      <td>102</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1521784</th>\n",
              "      <td>1459534</td>\n",
              "      <td>6767</td>\n",
              "      <td>18611</td>\n",
              "      <td>35515</td>\n",
              "      <td>383.76</td>\n",
              "      <td>5</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>90</td>\n",
              "      <td>140137.0</td>\n",
              "      <td>247</td>\n",
              "      <td>6484</td>\n",
              "      <td>0</td>\n",
              "      <td>5817</td>\n",
              "      <td>102</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1521785</th>\n",
              "      <td>580748</td>\n",
              "      <td>6881</td>\n",
              "      <td>7613</td>\n",
              "      <td>38076</td>\n",
              "      <td>513.80</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>90</td>\n",
              "      <td>180243.0</td>\n",
              "      <td>457</td>\n",
              "      <td>59333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>102</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1521786</th>\n",
              "      <td>785207</td>\n",
              "      <td>3210</td>\n",
              "      <td>77247</td>\n",
              "      <td>151506</td>\n",
              "      <td>391.88</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>90</td>\n",
              "      <td>155430.0</td>\n",
              "      <td>294</td>\n",
              "      <td>43529</td>\n",
              "      <td>0</td>\n",
              "      <td>2249</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1521787 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           txkey  acqic   bacno    cano  ...  ovrlt  scity  stocn  stscd\n",
              "0        1547337   6767  137279  176279  ...      0   5817    102      0\n",
              "1         361558   6032   95126   90258  ...      0   5817    102      0\n",
              "2        1833662   6215  104992  168046  ...      0   6580     38      0\n",
              "3        1119486   6717  158233   33494  ...      0   5800    102      0\n",
              "4        1047761   5975   78764  162106  ...      0   5817    102      0\n",
              "...          ...    ...     ...     ...  ...    ...    ...    ...    ...\n",
              "1521782  1927172   6618   65727  181927  ...      0   6593     75      0\n",
              "1521783   239570   6769   43220   18630  ...      0   5817    102      0\n",
              "1521784  1459534   6767   18611   35515  ...      0   5817    102      0\n",
              "1521785   580748   6881    7613   38076  ...      0      0    102      0\n",
              "1521786   785207   3210   77247  151506  ...      0   2249      6      0\n",
              "\n",
              "[1521787 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "_NStYykRd5-v",
        "outputId": "e59c0f6e-6b57-4a7f-bcc2-223d432cbd1b"
      },
      "source": [
        "df_y = df['fraud_ind']\n",
        "df_x = df.drop(['fraud_ind', 'txkey'], 1)\n",
        "df_x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>acqic</th>\n",
              "      <th>bacno</th>\n",
              "      <th>cano</th>\n",
              "      <th>conam</th>\n",
              "      <th>contp</th>\n",
              "      <th>csmcu</th>\n",
              "      <th>ecfg</th>\n",
              "      <th>etymd</th>\n",
              "      <th>flbmk</th>\n",
              "      <th>flg_3dsmk</th>\n",
              "      <th>hcefg</th>\n",
              "      <th>insfg</th>\n",
              "      <th>iterm</th>\n",
              "      <th>locdt</th>\n",
              "      <th>loctm</th>\n",
              "      <th>mcc</th>\n",
              "      <th>mchno</th>\n",
              "      <th>ovrlt</th>\n",
              "      <th>scity</th>\n",
              "      <th>stocn</th>\n",
              "      <th>stscd</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6767</td>\n",
              "      <td>137279</td>\n",
              "      <td>176279</td>\n",
              "      <td>785.96</td>\n",
              "      <td>5</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>70602.0</td>\n",
              "      <td>191</td>\n",
              "      <td>16615</td>\n",
              "      <td>0</td>\n",
              "      <td>5817</td>\n",
              "      <td>102</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6032</td>\n",
              "      <td>95126</td>\n",
              "      <td>90258</td>\n",
              "      <td>325.94</td>\n",
              "      <td>5</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>192920.0</td>\n",
              "      <td>251</td>\n",
              "      <td>78641</td>\n",
              "      <td>0</td>\n",
              "      <td>5817</td>\n",
              "      <td>102</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6215</td>\n",
              "      <td>104992</td>\n",
              "      <td>168046</td>\n",
              "      <td>288.05</td>\n",
              "      <td>5</td>\n",
              "      <td>62</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>160124.0</td>\n",
              "      <td>380</td>\n",
              "      <td>54238</td>\n",
              "      <td>0</td>\n",
              "      <td>6580</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6717</td>\n",
              "      <td>158233</td>\n",
              "      <td>33494</td>\n",
              "      <td>796.90</td>\n",
              "      <td>5</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>153353.0</td>\n",
              "      <td>304</td>\n",
              "      <td>33656</td>\n",
              "      <td>0</td>\n",
              "      <td>5800</td>\n",
              "      <td>102</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5975</td>\n",
              "      <td>78764</td>\n",
              "      <td>162106</td>\n",
              "      <td>800.02</td>\n",
              "      <td>5</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>191448.0</td>\n",
              "      <td>263</td>\n",
              "      <td>93792</td>\n",
              "      <td>0</td>\n",
              "      <td>5817</td>\n",
              "      <td>102</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1521782</th>\n",
              "      <td>6618</td>\n",
              "      <td>65727</td>\n",
              "      <td>181927</td>\n",
              "      <td>228.54</td>\n",
              "      <td>5</td>\n",
              "      <td>62</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>90</td>\n",
              "      <td>165427.0</td>\n",
              "      <td>192</td>\n",
              "      <td>65472</td>\n",
              "      <td>0</td>\n",
              "      <td>6593</td>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1521783</th>\n",
              "      <td>6769</td>\n",
              "      <td>43220</td>\n",
              "      <td>18630</td>\n",
              "      <td>939.74</td>\n",
              "      <td>5</td>\n",
              "      <td>62</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>90</td>\n",
              "      <td>124232.0</td>\n",
              "      <td>373</td>\n",
              "      <td>79200</td>\n",
              "      <td>0</td>\n",
              "      <td>5817</td>\n",
              "      <td>102</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1521784</th>\n",
              "      <td>6767</td>\n",
              "      <td>18611</td>\n",
              "      <td>35515</td>\n",
              "      <td>383.76</td>\n",
              "      <td>5</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>90</td>\n",
              "      <td>140137.0</td>\n",
              "      <td>247</td>\n",
              "      <td>6484</td>\n",
              "      <td>0</td>\n",
              "      <td>5817</td>\n",
              "      <td>102</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1521785</th>\n",
              "      <td>6881</td>\n",
              "      <td>7613</td>\n",
              "      <td>38076</td>\n",
              "      <td>513.80</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>90</td>\n",
              "      <td>180243.0</td>\n",
              "      <td>457</td>\n",
              "      <td>59333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>102</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1521786</th>\n",
              "      <td>3210</td>\n",
              "      <td>77247</td>\n",
              "      <td>151506</td>\n",
              "      <td>391.88</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>90</td>\n",
              "      <td>155430.0</td>\n",
              "      <td>294</td>\n",
              "      <td>43529</td>\n",
              "      <td>0</td>\n",
              "      <td>2249</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1521787 rows × 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         acqic   bacno    cano   conam  ...  ovrlt  scity  stocn  stscd\n",
              "0         6767  137279  176279  785.96  ...      0   5817    102      0\n",
              "1         6032   95126   90258  325.94  ...      0   5817    102      0\n",
              "2         6215  104992  168046  288.05  ...      0   6580     38      0\n",
              "3         6717  158233   33494  796.90  ...      0   5800    102      0\n",
              "4         5975   78764  162106  800.02  ...      0   5817    102      0\n",
              "...        ...     ...     ...     ...  ...    ...    ...    ...    ...\n",
              "1521782   6618   65727  181927  228.54  ...      0   6593     75      0\n",
              "1521783   6769   43220   18630  939.74  ...      0   5817    102      0\n",
              "1521784   6767   18611   35515  383.76  ...      0   5817    102      0\n",
              "1521785   6881    7613   38076  513.80  ...      0      0    102      0\n",
              "1521786   3210   77247  151506  391.88  ...      0   2249      6      0\n",
              "\n",
              "[1521787 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4QKkY3Sd83C",
        "outputId": "88a92278-f74f-4173-b132-6fad297efa5d"
      },
      "source": [
        "# split train+val and test\n",
        "df_x_data, df_x_test = train_test_split(df_x, test_size=0.2, shuffle=False)\n",
        "df_y_data = df_y.loc[df_x_data.index]\n",
        "df_y_test = df_y.loc[df_x_test.index]\n",
        "\n",
        "# print(df_x_data)\n",
        "# print(df_x_test)\n",
        "# print(df_y_data)\n",
        "# print(df_y_test)\n",
        "\n",
        "#split train and val\n",
        "df_x_train, df_x_val = train_test_split(df_x_data, test_size=0.2, shuffle=False)\n",
        "df_y_train = df_y_data.loc[df_x_train.index]\n",
        "df_y_val = df_y_data.loc[df_x_val.index]\n",
        "\n",
        "\n",
        "print('df_x_train:')\n",
        "print(df_x_train)\n",
        "print('df_x_val:')\n",
        "print(df_x_val)\n",
        "print('df_x_test:')\n",
        "print(df_x_test)\n",
        "print('df_y_train:')\n",
        "print(df_y_train)\n",
        "print('df_y_val:')\n",
        "print(df_y_val)\n",
        "print('df_y_test:')\n",
        "print(df_y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "df_x_train:\n",
            "        acqic   bacno    cano    conam  ...  ovrlt  scity  stocn  stscd\n",
            "0        6767  137279  176279   785.96  ...      0   5817    102      0\n",
            "1        6032   95126   90258   325.94  ...      0   5817    102      0\n",
            "2        6215  104992  168046   288.05  ...      0   6580     38      0\n",
            "3        6717  158233   33494   796.90  ...      0   5800    102      0\n",
            "4        5975   78764  162106   800.02  ...      0   5817    102      0\n",
            "...       ...     ...     ...      ...  ...    ...    ...    ...    ...\n",
            "973938   6777   61498   91553  1154.25  ...      0   5817    102      0\n",
            "973939   6625   87717   81548   366.38  ...      0   2260    102      0\n",
            "973940   6769  110892  124186   352.55  ...      0   4907    102      0\n",
            "973941   6215   60807   10755   168.20  ...      0   6580     38      0\n",
            "973942   6769  121100  190558   834.05  ...      0   5817    102      0\n",
            "\n",
            "[973943 rows x 21 columns]\n",
            "df_x_val:\n",
            "         acqic   bacno    cano    conam  ...  ovrlt  scity  stocn  stscd\n",
            "973943    6769   63692  126110   370.84  ...      0   5858    102      0\n",
            "973944    5975   37219   66575  1012.88  ...      0   5817    102      0\n",
            "973945    6231  147317  191373  1193.97  ...      0   5817    102      0\n",
            "973946    6581   80877  148095   981.75  ...      0   5817    102      0\n",
            "973947    6189    6375  151060   686.70  ...      0   5817    102      0\n",
            "...        ...     ...     ...      ...  ...    ...    ...    ...    ...\n",
            "1217424   5975   43783  135161   726.90  ...      0   5817    102      0\n",
            "1217425   6189  156962  130978   747.35  ...      0   5817    102      0\n",
            "1217426   6189   55833   73570   778.01  ...      0   5817    102      0\n",
            "1217427   6189    8720   55314  1145.74  ...      0   5817    102      0\n",
            "1217428   6189   24129  129395   590.50  ...      0   5817    102      0\n",
            "\n",
            "[243486 rows x 21 columns]\n",
            "df_x_test:\n",
            "         acqic   bacno    cano    conam  ...  ovrlt  scity  stocn  stscd\n",
            "1217429   6769   66594  102307  1100.42  ...      0   5817    102      0\n",
            "1217430   6769   41842  147528  1647.46  ...      0   5817    102      0\n",
            "1217431   6769   49879   62792  2071.74  ...      0   3588    102      0\n",
            "1217432   6779  133873  211554  1485.11  ...      0   5817    102      0\n",
            "1217433   6716   69469   67755   625.98  ...      0   5820    102      0\n",
            "...        ...     ...     ...      ...  ...    ...    ...    ...    ...\n",
            "1521782   6618   65727  181927   228.54  ...      0   6593     75      0\n",
            "1521783   6769   43220   18630   939.74  ...      0   5817    102      0\n",
            "1521784   6767   18611   35515   383.76  ...      0   5817    102      0\n",
            "1521785   6881    7613   38076   513.80  ...      0      0    102      0\n",
            "1521786   3210   77247  151506   391.88  ...      0   2249      6      0\n",
            "\n",
            "[304358 rows x 21 columns]\n",
            "df_y_train:\n",
            "0         0\n",
            "1         0\n",
            "2         0\n",
            "3         0\n",
            "4         0\n",
            "         ..\n",
            "973938    0\n",
            "973939    0\n",
            "973940    0\n",
            "973941    0\n",
            "973942    0\n",
            "Name: fraud_ind, Length: 973943, dtype: int64\n",
            "df_y_val:\n",
            "973943     0\n",
            "973944     0\n",
            "973945     0\n",
            "973946     0\n",
            "973947     0\n",
            "          ..\n",
            "1217424    0\n",
            "1217425    0\n",
            "1217426    0\n",
            "1217427    0\n",
            "1217428    0\n",
            "Name: fraud_ind, Length: 243486, dtype: int64\n",
            "df_y_test:\n",
            "1217429    0\n",
            "1217430    0\n",
            "1217431    0\n",
            "1217432    0\n",
            "1217433    0\n",
            "          ..\n",
            "1521782    0\n",
            "1521783    0\n",
            "1521784    0\n",
            "1521785    0\n",
            "1521786    0\n",
            "Name: fraud_ind, Length: 304358, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GV-g_AZrGyIx"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import math\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "lr = 1e-2\n",
        "batch_size = 973943\n",
        "# batch_num = math.ceil(df_x_train.shape[0] / batch_size)\n",
        "max_epoch = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npDJym73c_ji",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "17ef5d0d-8849-4c3c-cc3c-af110c4a5565"
      },
      "source": [
        "x_train = torch.from_numpy(df_x_train.values).to(device)\n",
        "y_train = torch.from_numpy(df_y_train.values).to(device)\n",
        "loader = DataLoader(TensorDataset(x_train, y_train), batch_size=batch_size, shuffle=True)\n",
        "\n",
        "x_val = torch.from_numpy(df_x_val.values).to(device)\n",
        "y_val = torch.from_numpy(df_y_val.values).to(device)\n",
        "\n",
        "x_test = torch.from_numpy(df_x_test.values).to(device)\n",
        "y_test = torch.from_numpy(df_y_test.values).to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2c8cfd17aad3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_x_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_y_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_x_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_x_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjTXm1SLIFQn"
      },
      "source": [
        "# n = x_train.shape[1]\n",
        "n = 21\n",
        "class simpleNN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(simpleNN, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            # nn.BatchNorm1d(n),\n",
        "            nn.Linear(n, 10),\n",
        "            nn.BatchNorm1d(10),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(10,5),\n",
        "            nn.BatchNorm1d(5),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(5,2),\n",
        "            # nn.BatchNorm1d(2),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.y_pred = self.layers(x.float())\n",
        "        return self.y_pred\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss().to(device)\n",
        "model = simpleNN()\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gxNDYEbEzSB"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yS_itGWTpO0a",
        "outputId": "41d88147-a48a-4174-985a-b241c972e275"
      },
      "source": [
        "model.train()\n",
        "val_f1_max = 0\n",
        "for epoch in range(max_epoch):\n",
        "  e_loss = 0\n",
        "  e_acc = 0\n",
        "  e_prc = 0\n",
        "  e_rec = 0\n",
        "  e_f1 = 0\n",
        "\n",
        "  for x_batch, y_batch in loader:\n",
        "    current_size = y_batch.shape[0]\n",
        "    optimizer.zero_grad()\n",
        "    y_pred = model(x_batch)\n",
        "    y_scalar = []\n",
        "    for d in y_pred:\n",
        "      if d[0]>d[1]:\n",
        "        y_scalar.append(0)\n",
        "      else:\n",
        "        y_scalar.append(1)\n",
        "    \n",
        "    loss = loss_func(y_pred.double(), y_batch.flatten().long()).to(device)\n",
        "    e_loss += loss.item()\n",
        "    # loss = loss.float()\n",
        "\n",
        "    e_acc += accuracy_score(y_batch, y_scalar)\n",
        "    e_prc += precision_score(y_batch, y_scalar)\n",
        "    e_rec += recall_score(y_batch, y_scalar)\n",
        "    e_f1 += f1_score(y_batch, y_scalar)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  \n",
        "  e_acc = (e_acc / batch_num)\n",
        "  e_loss = (e_loss / batch_num)\n",
        "  e_prc = (e_prc / batch_num)\n",
        "  e_rec = (e_rec / batch_num)\n",
        "  e_f1 = (e_f1 / batch_num)\n",
        "  print('epoch: {}, loss: {}, acc: {}, prc: {}, rec: {}, f1: {}'.format(epoch, e_loss, e_acc, e_prc, e_rec, e_f1))\n",
        "\n",
        "  if epoch%10 == 0:\n",
        "    y_pred = model(x_val)\n",
        "    y_scalar = []\n",
        "    for d in y_pred:\n",
        "      if d[0]>d[1]:\n",
        "        y_scalar.append(0)\n",
        "      else:\n",
        "        y_scalar.append(1)\n",
        "    \n",
        "\n",
        "    val_loss = loss_func(y_pred.double(), y_val.flatten().long()).to(device)\n",
        "    val_acc = accuracy_score(y_val, y_scalar)\n",
        "    val_prc = precision_score(y_val, y_scalar)\n",
        "    val_rec = recall_score(y_val, y_scalar)\n",
        "    val_f1 = f1_score(y_val, y_scalar)\n",
        "    print(\"================validation================\")\n",
        "    print('epoch: {}, loss: {}, acc: {}, prc: {}, rec: {}, f1: {}'.format(epoch, val_loss, val_acc, val_prc, val_rec, val_f1))\n",
        "    if val_f1 > val_f1_max:\n",
        "        val_f1_max = val_f1\n",
        "        torch.save(model.state_dict(), '/content/drive/My Drive/fintech-introduction/term-project/simpleNN_s1.pkl')\n",
        "        print('update_file')\n",
        "    print('==========================================')\n",
        "\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, loss: 0.6282658860893092, acc: 0.9848101993648499, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "================validation================\n",
            "epoch: 0, loss: 0.626873199110931, acc: 0.9887550002874909, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "==========================================\n",
            "epoch: 1, loss: 0.6273762951896893, acc: 0.9848122528731148, prc: 0.0, rec: 0.0, f1: 0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 2, loss: 0.6264873041293019, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 3, loss: 0.625598916167319, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 4, loss: 0.6247111693692733, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 5, loss: 0.6238240647238665, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 6, loss: 0.6229375606847106, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 7, loss: 0.622051603519325, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 8, loss: 0.6211661255532513, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 9, loss: 0.6202810793936988, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 10, loss: 0.6193964184742241, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 11, loss: 0.6185120949359739, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 12, loss: 0.6176280618606241, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 13, loss: 0.6167442847934012, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 14, loss: 0.6158607315712471, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 15, loss: 0.6149773623837781, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 16, loss: 0.6140941648179417, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 17, loss: 0.6132111275978944, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 18, loss: 0.6123282392138674, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 19, loss: 0.6114455051871268, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 20, loss: 0.6105629464733365, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 21, loss: 0.6096805848144548, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 22, loss: 0.6087984595935874, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 23, loss: 0.6079166335467414, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 24, loss: 0.6070351849264651, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 25, loss: 0.6061542018828469, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 26, loss: 0.6052737910996305, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 27, loss: 0.6043940745675129, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 28, loss: 0.603515163571376, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 29, loss: 0.6026371838144903, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 30, loss: 0.601760240106572, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 31, loss: 0.6008844374827929, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 32, loss: 0.600009837018079, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 33, loss: 0.5991365139461721, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 34, loss: 0.5982644920977438, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 35, loss: 0.5973937975131682, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 36, loss: 0.5965244506580193, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 37, loss: 0.595656451109337, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 38, loss: 0.5947898144327594, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 39, loss: 0.5939245541816517, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 40, loss: 0.5930606754211442, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 41, loss: 0.5921982077664267, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 42, loss: 0.5913371619114667, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 43, loss: 0.5904775740242778, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 44, loss: 0.589619469445477, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 45, loss: 0.5887628791922658, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 46, loss: 0.5879078304708063, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 47, loss: 0.5870543580024128, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 48, loss: 0.5862024795244815, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 49, loss: 0.5853522334021476, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 50, loss: 0.5845036680003014, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 51, loss: 0.5836568133377402, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 52, loss: 0.582811732160183, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 53, loss: 0.5819684634543726, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 54, loss: 0.5811270782576711, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 55, loss: 0.5802876304541001, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 56, loss: 0.579450189621535, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 57, loss: 0.5786148005831766, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 58, loss: 0.5777815256410688, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 59, loss: 0.5769504224777274, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 60, loss: 0.5761215229962074, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 61, loss: 0.5752948681019644, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 62, loss: 0.5744704794662592, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 63, loss: 0.5736483648282086, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 64, loss: 0.5728285279427996, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 65, loss: 0.5720109580071167, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 66, loss: 0.5711956320853437, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 67, loss: 0.5703825141998957, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 68, loss: 0.5695715840975035, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 69, loss: 0.5687627878634254, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 70, loss: 0.5679560880429569, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 71, loss: 0.567151438837372, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 72, loss: 0.5663488024123734, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 73, loss: 0.5655481434729289, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 74, loss: 0.5647494139350231, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 75, loss: 0.5639525817396024, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 76, loss: 0.5631576321835422, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 77, loss: 0.5623645317553957, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 78, loss: 0.5615732758558564, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 79, loss: 0.5607838565485114, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 80, loss: 0.5599962861782064, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 81, loss: 0.559210586863706, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 82, loss: 0.5584267886195655, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 83, loss: 0.5576449480583558, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 84, loss: 0.5568651206851429, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 85, loss: 0.5560873911527887, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 86, loss: 0.5553118538590834, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 87, loss: 0.5545386196086963, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 88, loss: 0.5537677969942879, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 89, loss: 0.5529995300608329, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 90, loss: 0.552233950191363, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 91, loss: 0.551471169097172, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 92, loss: 0.5507113124154993, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 93, loss: 0.5499544562831974, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 94, loss: 0.549200666538871, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 95, loss: 0.5484499541613386, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 96, loss: 0.5477022878627781, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 97, loss: 0.5469576069634636, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 98, loss: 0.5462158055621664, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 99, loss: 0.5454767532790126, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e8qOnJY9ClG"
      },
      "source": [
        "### Show the performance on testing set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7jhXyNeR95k"
      },
      "source": [
        "model_test = simpleNN()\n",
        "model_test.load_state_dict(torch.load('/content/drive/My Drive/fintech-introduction/term-project/simpleNN_s1.pkl'))\n",
        "model_test = model_test.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWEFTfv4Adyt"
      },
      "source": [
        "y_pred = model_test(x_test)\n",
        "y_scalar = []\n",
        "for d in y_pred:\n",
        "  if d[0]>d[1]:\n",
        "    y_scalar.append(0)\n",
        "  else:\n",
        "    y_scalar.append(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaCmD1EqBBXr",
        "outputId": "9110df0c-5eed-46e7-bf9f-a4960f60a7c9"
      },
      "source": [
        "y_target = y_test\n",
        "cm = confusion_matrix(y_target, y_scalar)\n",
        "# row: actually, column: predict, the smaller class will be the target for counting the following indexies\n",
        "print(cm)\n",
        "\n",
        "# these libraries will automatically take the fewer class to evaluate the performance\n",
        "print('accuracy_score: ', accuracy_score(y_target, y_scalar))\n",
        "print(\"precision_score\", precision_score(y_target, y_scalar))\n",
        "print(\"recall_score\",    recall_score(y_target, y_scalar))\n",
        "print(\"f1_score\",        f1_score(y_target, y_scalar))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[301529      0]\n",
            " [  2829      0]]\n",
            "accuracy_score:  0.9907050250034499\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "precision_score 0.0\n",
            "recall_score 0.0\n",
            "f1_score 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJaumEzcH1a_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80d2aa63-9b50-426b-bd39-fa4785e7a7a8"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "simpleNN(\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=21, out_features=10, bias=True)\n",
            "    (1): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Sigmoid()\n",
            "    (3): Linear(in_features=10, out_features=5, bias=True)\n",
            "    (4): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): Sigmoid()\n",
            "    (6): Linear(in_features=5, out_features=2, bias=True)\n",
            "    (7): Sigmoid()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWFl1Ts87zs6"
      },
      "source": [
        "# Data Processing scenario 2\n",
        "- Base on scenerio 1\n",
        "- Balance two class\n",
        "- Sample 40000 data in 64%(0.8 * 0.8) training data\n",
        "- 16%(0.8 * 0.2) to validate\n",
        "- 20% to test\n",
        "- f1 : 0.13"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PqfTsIU75yq",
        "outputId": "da13d204-78e5-4601-b766-ffc681243402"
      },
      "source": [
        "# Balance two #example in two class\n",
        "# df_y_train\n",
        "df_fraud = df_x_train.loc[df_y_train == 1]\n",
        "df_non_fraud = df_x_train.loc[df_y_train == 0].sample(n=df_fraud.shape[0])\n",
        "df_x_train_balance = pd.concat([df_fraud, df_non_fraud])\n",
        "df_y_train_balance = pd.concat([df_y_train.loc[df_fraud.index], df_y_train.loc[df_non_fraud.index]])\n",
        "df_fraud, df_non_fraud, df_x_train_balance, df_y_train_balance\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(        acqic   bacno    cano    conam  contp  ...  stocn  stscd  hh  mm  ss\n",
              " 60       6215   16431   58243     0.00      5  ...     38      0  17  13  29\n",
              " 157      6760  147298  155705     0.00      5  ...     75      0  15  21   0\n",
              " 208      6210   37935   60807   785.90      5  ...     27      0  17  23  18\n",
              " 224      3348  121994   20387   443.90      5  ...     46      0  21  58   5\n",
              " 274      3191  159517  146746     0.08      4  ...     52      2  21  28   7\n",
              " ...       ...     ...     ...      ...    ...  ...    ...    ...  ..  ..  ..\n",
              " 973222   5643    2671  117176   723.75      4  ...     38      0  21   4  18\n",
              " 973509   6215  111181  207376   407.87      5  ...     46      0  13  39  33\n",
              " 973717   6760   98920  129272  2023.54      5  ...     38      2  14  34  11\n",
              " 973843   6760   37464  193146   556.79      5  ...     75      0   5  28  56\n",
              " 973924   6760   68389  160902   603.86      5  ...     75      0   2  31  36\n",
              " \n",
              " [14789 rows x 23 columns],\n",
              "         acqic   bacno    cano   conam  contp  ...  stocn  stscd  hh  mm  ss\n",
              " 819345   6716   65520  109771  689.86      5  ...    102      0  10  11  13\n",
              " 139172   6769   18650  131680  341.25      6  ...    102      0  17  23   1\n",
              " 872534   5975  125738   45751  774.70      5  ...    102      0  15  39  54\n",
              " 883943   6881   51472  166052  513.80      5  ...    102      0  11  28  20\n",
              " 252781   6779  142996   55328  592.25      5  ...    102      0  18  45  29\n",
              " ...       ...     ...     ...     ...    ...  ...    ...    ...  ..  ..  ..\n",
              " 490551   6767   48929   33909  149.14      5  ...    102      0  16   2  17\n",
              " 672428   6189   26216  105349  763.10      5  ...    102      0  16  45  27\n",
              " 947772   6189  140366  104651  636.82      2  ...    102      0  13  11  46\n",
              " 315753   6777  157794  206013  283.91      5  ...    102      0  14  47   0\n",
              " 512008   6769   48495  113844  443.34      5  ...    102      0  19  36   6\n",
              " \n",
              " [14789 rows x 23 columns],\n",
              "         acqic   bacno    cano   conam  contp  ...  stocn  stscd  hh  mm  ss\n",
              " 60       6215   16431   58243    0.00      5  ...     38      0  17  13  29\n",
              " 157      6760  147298  155705    0.00      5  ...     75      0  15  21   0\n",
              " 208      6210   37935   60807  785.90      5  ...     27      0  17  23  18\n",
              " 224      3348  121994   20387  443.90      5  ...     46      0  21  58   5\n",
              " 274      3191  159517  146746    0.08      4  ...     52      2  21  28   7\n",
              " ...       ...     ...     ...     ...    ...  ...    ...    ...  ..  ..  ..\n",
              " 490551   6767   48929   33909  149.14      5  ...    102      0  16   2  17\n",
              " 672428   6189   26216  105349  763.10      5  ...    102      0  16  45  27\n",
              " 947772   6189  140366  104651  636.82      2  ...    102      0  13  11  46\n",
              " 315753   6777  157794  206013  283.91      5  ...    102      0  14  47   0\n",
              " 512008   6769   48495  113844  443.34      5  ...    102      0  19  36   6\n",
              " \n",
              " [29578 rows x 23 columns],\n",
              " 60        1\n",
              " 157       1\n",
              " 208       1\n",
              " 224       1\n",
              " 274       1\n",
              "          ..\n",
              " 490551    0\n",
              " 672428    0\n",
              " 947772    0\n",
              " 315753    0\n",
              " 512008    0\n",
              " Name: fraud_ind, Length: 29578, dtype: int64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfaTlfd48OCm"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import math\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "lr = 1e-2\n",
        "batch_size = 29578\n",
        "batch_num = math.ceil(df_x_train_balance.shape[0] / batch_size)\n",
        "max_epoch = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuv1884u8bsX"
      },
      "source": [
        "x_train = torch.from_numpy(df_x_train_balance.values).to(device)\n",
        "y_train = torch.from_numpy(df_y_train_balance.values).to(device)\n",
        "loader = DataLoader(TensorDataset(x_train, y_train), batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTU6ceFS8vll"
      },
      "source": [
        "n = x_train.shape[1]\n",
        "class simpleNN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(simpleNN, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.BatchNorm1d(n),\n",
        "            nn.Linear(n, 10),\n",
        "            nn.BatchNorm1d(10),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(10,5),\n",
        "            nn.BatchNorm1d(5),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(5,2),\n",
        "            # nn.BatchNorm1d(2),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.y_pred = self.conv(x.float())\n",
        "        return self.y_pred\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss().to(device)\n",
        "model = simpleNN()\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZU1sPl2A9BBV",
        "outputId": "a8e075bc-9f8c-4cc0-90ea-a12e1c251f6c"
      },
      "source": [
        "model.train()\n",
        "val_f1_max = 0\n",
        "for epoch in range(max_epoch):\n",
        "  e_loss = 0\n",
        "  e_acc = 0\n",
        "  e_prc = 0\n",
        "  e_rec = 0\n",
        "  e_f1 = 0\n",
        "\n",
        "  for x_batch, y_batch in loader:\n",
        "    current_size = y_batch.shape[0]\n",
        "    optimizer.zero_grad()\n",
        "    y_pred = model(x_batch)\n",
        "    y_scalar = []\n",
        "    for d in y_pred:\n",
        "      if d[0]>d[1]:\n",
        "        y_scalar.append(0)\n",
        "      else:\n",
        "        y_scalar.append(1)\n",
        "    \n",
        "    loss = loss_func(y_pred.double(), y_batch.flatten().long()).to(device)\n",
        "    e_loss += loss.item()\n",
        "    # loss = loss.float()\n",
        "\n",
        "    e_acc += accuracy_score(y_batch, y_scalar)\n",
        "    e_prc += precision_score(y_batch, y_scalar)\n",
        "    e_rec += recall_score(y_batch, y_scalar)\n",
        "    e_f1 += f1_score(y_batch, y_scalar)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  \n",
        "  e_acc = (e_acc / batch_num)\n",
        "  e_loss = (e_loss / batch_num)\n",
        "  e_prc = (e_prc / batch_num)\n",
        "  e_rec = (e_rec / batch_num)\n",
        "  e_f1 = (e_f1 / batch_num)\n",
        "  print('epoch: {}, loss: {}, acc: {}, prc: {}, rec: {}, f1: {}'.format(epoch, e_loss, e_acc, e_prc, e_rec, e_f1))\n",
        "\n",
        "  if epoch%10 == 0:\n",
        "    y_pred = model(x_val)\n",
        "    y_scalar = []\n",
        "    for d in y_pred:\n",
        "      if d[0]>d[1]:\n",
        "        y_scalar.append(0)\n",
        "      else:\n",
        "        y_scalar.append(1)\n",
        "    \n",
        "\n",
        "    val_loss = loss_func(y_pred.double(), y_val.flatten().long()).to(device)\n",
        "    val_acc = accuracy_score(y_val, y_scalar)\n",
        "    val_prc = precision_score(y_val, y_scalar)\n",
        "    val_rec = recall_score(y_val, y_scalar)\n",
        "    val_f1 = f1_score(y_val, y_scalar)\n",
        "    print(\"================validation================\")\n",
        "    print('epoch: {}, loss: {}, acc: {}, prc: {}, rec: {}, f1: {}'.format(epoch, val_loss, val_acc, val_prc, val_rec, val_f1))\n",
        "    if val_f1 > val_f1_max:\n",
        "        val_f1_max = val_f1\n",
        "        torch.save(model.state_dict(), '/content/drive/My Drive/fintech-introduction/term-project/simpleNN_s2.pkl')\n",
        "        print('update_file')\n",
        "    print('==========================================')\n",
        "\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, loss: 0.6899419872871889, acc: 0.5014537832172561, prc: 0.8771929824561403, rec: 0.00338089120292109, f1: 0.006735821096591675\n",
            "================validation================\n",
            "epoch: 0, loss: 0.6155196402877753, acc: 0.9854734974495454, prc: 0.06616052060737528, rec: 0.02228717573986116, f1: 0.033342443290516534\n",
            "update_file\n",
            "==========================================\n",
            "epoch: 1, loss: 0.6890631957554803, acc: 0.5016228277774021, prc: 0.8870967741935484, rec: 0.003718980323213199, f1: 0.007406908625681772\n",
            "epoch: 2, loss: 0.6881848695415441, acc: 0.5018256812495774, prc: 0.8857142857142857, rec: 0.004192305091622151, f1: 0.008345110707315431\n",
            "epoch: 3, loss: 0.6873078947858076, acc: 0.5018932990736358, prc: 0.8589743589743589, rec: 0.0045303942119142605, f1: 0.009013250823972556\n",
            "epoch: 4, loss: 0.6864325731991796, acc: 0.5021637703698695, prc: 0.8555555555555555, rec: 0.005206572452498478, f1: 0.010350157940721822\n",
            "epoch: 5, loss: 0.6855590818679136, acc: 0.502400432754074, prc: 0.8317757009345794, rec: 0.00601798634119954, f1: 0.011949516648764768\n",
            "epoch: 6, loss: 0.6846877221323313, acc: 0.5027723307863953, prc: 0.8306451612903226, rec: 0.0069646358780174455, f1: 0.013813451351170122\n",
            "epoch: 7, loss: 0.6838188845045586, acc: 0.5032118466427751, prc: 0.8145695364238411, rec: 0.008316992359185881, f1: 0.01646586345381526\n",
            "epoch: 8, loss: 0.6829529973162702, acc: 0.5041246872675638, prc: 0.8315217391304348, rec: 0.010345527080938536, f1: 0.02043678621518734\n",
            "epoch: 9, loss: 0.6820905224667907, acc: 0.5048684833322064, prc: 0.839622641509434, rec: 0.01203597268239908, f1: 0.023731751216585564\n",
            "epoch: 10, loss: 0.6812319814221014, acc: 0.5055446615727905, prc: 0.853448275862069, rec: 0.013388329163567516, f1: 0.026363091671659677\n",
            "================validation================\n",
            "epoch: 10, loss: 0.6188415893999001, acc: 0.9684293963513303, prc: 0.057719799857040746, rec: 0.11801242236024845, f1: 0.07752310092403697\n",
            "update_file\n",
            "==========================================\n",
            "epoch: 11, loss: 0.6803779297950114, acc: 0.5062884576374332, prc: 0.8549618320610687, rec: 0.015146392589086483, f1: 0.029765464088764865\n",
            "epoch: 12, loss: 0.6795289050967929, acc: 0.5071674893501927, prc: 0.8557046979865772, rec: 0.01724254513489756, f1: 0.03380393716444621\n",
            "epoch: 13, loss: 0.6786853816721345, acc: 0.5085536547433903, prc: 0.8645533141210374, rec: 0.02028534721752654, f1: 0.039640591966173366\n",
            "epoch: 14, loss: 0.6778477445628314, acc: 0.5102102914328217, prc: 0.8719211822660099, rec: 0.02393670971668132, f1: 0.046594274432379075\n",
            "epoch: 15, loss: 0.677016284826356, acc: 0.5120021637703699, prc: 0.8752642706131079, rec: 0.027993779160186624, f1: 0.05425239156073909\n",
            "epoch: 16, loss: 0.6761912119443195, acc: 0.5138954628440057, prc: 0.8784530386740331, rec: 0.0322537020758672, f1: 0.06222280198278111\n",
            "epoch: 17, loss: 0.6753726670732276, acc: 0.5160930421259043, prc: 0.8814102564102564, rec: 0.03718980323213199, f1: 0.07136832543956399\n",
            "epoch: 18, loss: 0.6745607483222105, acc: 0.5180877679356278, prc: 0.8783592644978784, rec: 0.041990668740279936, f1: 0.08014971605575633\n",
            "epoch: 19, loss: 0.6737555392139732, acc: 0.520352965041585, prc: 0.881979695431472, rec: 0.04699438772060315, f1: 0.08923412723887783\n",
            "epoch: 20, loss: 0.6729571256569858, acc: 0.5247481236053824, prc: 0.8918629550321199, rec: 0.05632564744066536, f1: 0.10595942250206704\n",
            "================validation================\n",
            "epoch: 20, loss: 0.6218412306774075, acc: 0.9306489900856723, prc: 0.06381404525556446, rec: 0.37815126050420167, f1: 0.10920025321797848\n",
            "update_file\n",
            "==========================================\n",
            "epoch: 21, loss: 0.6721656179089948, acc: 0.5284332950165663, prc: 0.8948356807511737, rec: 0.06443978632767597, f1: 0.12022202598713257\n",
            "epoch: 22, loss: 0.6713811538912363, acc: 0.531577523835283, prc: 0.892436974789916, rec: 0.07181012915004395, f1: 0.13292446335815758\n",
            "epoch: 23, loss: 0.6706039041497883, acc: 0.5349584150382041, prc: 0.8893072289156626, rec: 0.07985665021299615, f1: 0.14655332878327232\n",
            "epoch: 24, loss: 0.6698340727085497, acc: 0.5382716884170667, prc: 0.8866120218579235, rec: 0.0877679356278315, f1: 0.15972435857995448\n",
            "epoch: 25, loss: 0.669071891020372, acc: 0.5419230509162215, prc: 0.8865336658354115, rec: 0.0961525458110758, f1: 0.17348868419447325\n",
            "epoch: 26, loss: 0.6683176124641509, acc: 0.5457434579755224, prc: 0.8828522920203735, rec: 0.10548380553113801, f1: 0.18845131674317467\n",
            "epoch: 27, loss: 0.6675715115158644, acc: 0.5492933937385895, prc: 0.8824763903462749, rec: 0.11373318006626547, f1: 0.20149745432764302\n",
            "epoch: 28, loss: 0.6668338832172666, acc: 0.5536209344783285, prc: 0.8842054263565892, rec: 0.12340252890661979, f1: 0.21657865068533796\n",
            "epoch: 29, loss: 0.666105034389912, acc: 0.5578132395699507, prc: 0.8847884788478848, rec: 0.13293664209885725, f1: 0.23114455352419025\n",
            "epoch: 30, loss: 0.6653852774308433, acc: 0.5624788694299817, prc: 0.8843594009983361, rec: 0.14375549394820475, f1: 0.24730995172453904\n",
            "================validation================\n",
            "epoch: 30, loss: 0.6240289858907508, acc: 0.9007663684975727, prc: 0.06896551724137931, rec: 0.6262331019364268, f1: 0.12424791591156215\n",
            "update_file\n",
            "==========================================\n",
            "epoch: 31, loss: 0.6646749276478376, acc: 0.5674487794982758, prc: 0.8835063437139562, rec: 0.1553857596862533, f1: 0.26428982173663024\n",
            "epoch: 32, loss: 0.663974307080986, acc: 0.5724186895665697, prc: 0.8833214030064424, rec: 0.166880789776185, f1: 0.2807257009611557\n",
            "epoch: 33, loss: 0.663283723339735, acc: 0.5766786124822503, prc: 0.8813046402151984, rec: 0.17722631685712353, f1: 0.29510780836570394\n",
            "epoch: 34, loss: 0.6626034675629954, acc: 0.5817161403746027, prc: 0.8815914114303758, rec: 0.18878896477111368, f1: 0.3109824014257073\n",
            "epoch: 35, loss: 0.6619338112762578, acc: 0.5860436811143417, prc: 0.8795108857739338, rec: 0.1994049631482859, f1: 0.32510197332157426\n",
            "epoch: 36, loss: 0.6612749988040723, acc: 0.5900669416458179, prc: 0.877123442808607, rec: 0.20948001893299073, f1: 0.33819114677146445\n",
            "epoch: 37, loss: 0.6606272408269477, acc: 0.5935830684968558, prc: 0.8736501079913607, rec: 0.21881127865305294, f1: 0.34997025901692536\n",
            "epoch: 38, loss: 0.6599907091717333, acc: 0.5989248765974711, prc: 0.8751282051282051, rec: 0.2307796335113936, f1: 0.36524158595965545\n",
            "epoch: 39, loss: 0.6593655322052812, acc: 0.6043343025221448, prc: 0.8752431906614786, rec: 0.24335654878626006, f1: 0.3808264113009894\n",
            "epoch: 40, loss: 0.6587518011589238, acc: 0.6086956521739131, prc: 0.8721926371845334, rec: 0.2547163432280749, f1: 0.39428511618170403\n",
            "================validation================\n",
            "epoch: 40, loss: 0.6251442319862838, acc: 0.877684959299508, prc: 0.06357915120219461, rec: 0.7197661673364998, f1: 0.11683767273589941\n",
            "==========================================\n",
            "epoch: 41, loss: 0.6581495503379907, acc: 0.6126851037933599, prc: 0.8709103049187625, rec: 0.2645885455406045, f1: 0.4058707602945753\n",
            "epoch: 42, loss: 0.6575587798748576, acc: 0.6164717019406315, prc: 0.8701912744465936, rec: 0.2737845696125499, f1: 0.4165209340602819\n",
            "epoch: 43, loss: 0.6569794377515279, acc: 0.6212387585367503, prc: 0.8713753106876554, rec: 0.2844681858137805, f1: 0.4289136973033593\n",
            "epoch: 44, loss: 0.6564114298773226, acc: 0.6264115220772195, prc: 0.8724845586770273, rec: 0.29609845155182907, f1: 0.44214458804523427\n",
            "epoch: 45, loss: 0.6558546237422364, acc: 0.6317533301778349, prc: 0.8726333907056799, rec: 0.30854013117857865, f1: 0.4558896992706564\n",
            "epoch: 46, loss: 0.6553088488786184, acc: 0.6364527689498952, prc: 0.8737037037037036, rec: 0.31902089390763405, f1: 0.4673832284907623\n",
            "epoch: 47, loss: 0.6547738994162374, acc: 0.6427074176752993, prc: 0.8758682101513803, rec: 0.3325444587193184, f1: 0.4820623407175065\n",
            "epoch: 48, loss: 0.6542495348211734, acc: 0.6468659138548921, prc: 0.8755186721991701, rec: 0.342416661031848, f1: 0.4922957274097117\n",
            "epoch: 49, loss: 0.6537354922001624, acc: 0.6510244100344851, prc: 0.8758202927814235, rec: 0.3519507742240855, f1: 0.5021223229789699\n",
            "epoch: 50, loss: 0.6532314752410727, acc: 0.6549800527419027, prc: 0.8763546798029557, rec: 0.36087632699979716, f1: 0.5112313808132574\n",
            "================validation================\n",
            "epoch: 50, loss: 0.6256153471425012, acc: 0.8450177833633146, prc: 0.05507106353766749, rec: 0.7913774205334307, f1: 0.10297613387848246\n",
            "==========================================\n",
            "epoch: 51, loss: 0.652737172799217, acc: 0.6593075934816418, prc: 0.877806286080821, rec: 0.3701399688958009, f1: 0.5207134363852557\n",
            "epoch: 52, loss: 0.6522522491827848, acc: 0.6627899114206505, prc: 0.8771737427541908, rec: 0.37859219690310364, f1: 0.5289061023993954\n",
            "epoch: 53, loss: 0.6517763588557813, acc: 0.66623842044763, prc: 0.8765507734722009, rec: 0.38697680708634796, f1: 0.536917159208181\n",
            "epoch: 54, loss: 0.6513091451668085, acc: 0.6701264453309892, prc: 0.8772113943028486, rec: 0.39563188856582593, f1: 0.5453189803811921\n",
            "epoch: 55, loss: 0.6508502392708625, acc: 0.6735749543579688, prc: 0.8776110620770815, rec: 0.40340793833254446, f1: 0.5527400750451661\n",
            "epoch: 56, loss: 0.6503992765061407, acc: 0.6775644059774156, prc: 0.8780593147135042, rec: 0.4124011089323146, f1: 0.5612146307798482\n",
            "epoch: 57, loss: 0.6499558927183641, acc: 0.6813171952126581, prc: 0.8781554082639966, rec: 0.42105619041179254, f1: 0.5691956124314442\n",
            "epoch: 58, loss: 0.6495197265970847, acc: 0.6850361755358713, prc: 0.8787543252595156, rec: 0.42930556494692, f1: 0.5768147542472972\n",
            "epoch: 59, loss: 0.6490904372168429, acc: 0.6880789776185002, prc: 0.8786929884275017, rec: 0.4364054364730543, f1: 0.5831752055660975\n",
            "epoch: 60, loss: 0.6486676820528245, acc: 0.6914260599093921, prc: 0.878475935828877, rec: 0.4443167218878896, f1: 0.5901477390093852\n",
            "================validation================\n",
            "epoch: 60, loss: 0.6259603542646007, acc: 0.8147860657286251, prc: 0.04872800102271275, rec: 0.8355864084764341, f1: 0.09208592538906002\n",
            "==========================================\n",
            "epoch: 61, loss: 0.6482511452100784, acc: 0.6938941104875245, prc: 0.8783480670273123, rec: 0.4501318547569139, f1: 0.595225321888412\n",
            "epoch: 62, loss: 0.6478405257623526, acc: 0.6962607343295693, prc: 0.8779789035030603, rec: 0.45587936980187976, f1: 0.600142424781912\n",
            "epoch: 63, loss: 0.6474355420113773, acc: 0.6983568868753803, prc: 0.8774932441127268, rec: 0.46108594225437827, f1: 0.6045212765957447\n",
            "epoch: 64, loss: 0.6470359274713766, acc: 0.7011630265738048, prc: 0.87677304964539, rec: 0.4681181959564541, f1: 0.6103592682389243\n",
            "epoch: 65, loss: 0.6466414332663426, acc: 0.7037663128000541, prc: 0.876734591823978, rec: 0.4742038001217121, f1: 0.6154993856415657\n",
            "epoch: 66, loss: 0.6462518362071107, acc: 0.7065386435864494, prc: 0.8769591509317537, rec: 0.48049225775914534, f1: 0.6208282369386685\n",
            "epoch: 67, loss: 0.6458669196396103, acc: 0.7099533437013997, prc: 0.8770949720670391, rec: 0.48833592534992226, f1: 0.6273726273726274\n",
            "epoch: 68, loss: 0.6454864838239243, acc: 0.7134018527283792, prc: 0.8778735632183908, rec: 0.49577388599634864, f1: 0.6336804805323885\n",
            "epoch: 69, loss: 0.6451103373780778, acc: 0.7167827439313003, prc: 0.8782444549315715, rec: 0.5033470822908919, f1: 0.6399312271652697\n",
            "epoch: 70, loss: 0.6447382978831836, acc: 0.7207721955507472, prc: 0.8790341304852566, rec: 0.5120021637703699, f1: 0.6470965260863992\n",
            "================validation================\n",
            "epoch: 70, loss: 0.6263566577347114, acc: 0.801729873586161, prc: 0.04828694427361279, rec: 0.8892948483741323, f1: 0.09160018064127652\n",
            "==========================================\n",
            "epoch: 71, loss: 0.6443701963010944, acc: 0.7242207045777267, prc: 0.8795787545787546, rec: 0.5195753600649131, f1: 0.6532624867162593\n",
            "epoch: 72, loss: 0.6440058600862023, acc: 0.7278044492528231, prc: 0.8799909767651704, rec: 0.5275542633038068, f1: 0.6596491228070175\n",
            "epoch: 73, loss: 0.6436451207876346, acc: 0.7311853404557441, prc: 0.8809046345811051, rec: 0.5346541348299412, f1: 0.6654323585104145\n",
            "epoch: 74, loss: 0.6432878215916451, acc: 0.7338562445060518, prc: 0.881606532053404, rec: 0.5402664142267902, f1: 0.6699647828274359\n",
            "epoch: 75, loss: 0.6429337927989904, acc: 0.7353776455473663, prc: 0.8813540753724802, rec: 0.5439853945500034, f1: 0.6727432370280553\n",
            "epoch: 76, loss: 0.6425828756280679, acc: 0.7371019000608561, prc: 0.8813485589994562, rec: 0.5479748461694502, f1: 0.6757838559039359\n",
            "epoch: 77, loss: 0.6422349047824658, acc: 0.7384880654540537, prc: 0.881462253947653, rec: 0.5510852660761377, f1: 0.678177657582692\n",
            "epoch: 78, loss: 0.6418897161931417, acc: 0.7399756575833389, prc: 0.8816129032258064, rec: 0.5543985394550003, f1: 0.6807256424093984\n",
            "epoch: 79, loss: 0.6415471495053349, acc: 0.7413618229765366, prc: 0.8818872365464855, rec: 0.5573737237135709, f1: 0.6830460722572091\n",
            "epoch: 80, loss: 0.6412070452613796, acc: 0.7425113259855298, prc: 0.8821523708044752, rec: 0.559807965379674, f1: 0.6849507735583683\n",
            "================validation================\n",
            "epoch: 80, loss: 0.6268580130076349, acc: 0.7959882703728346, prc: 0.048048221541779804, rec: 0.9115820241139935, f1: 0.09128494072881604\n",
            "==========================================\n",
            "epoch: 81, loss: 0.6408692421607414, acc: 0.7434917844343769, prc: 0.8818663838812301, rec: 0.5623098248698357, f1: 0.6867335562987736\n",
            "epoch: 82, loss: 0.6405335750646599, acc: 0.744303198323078, prc: 0.882085448392555, rec: 0.5640002704712962, f1: 0.6880593936894205\n",
            "epoch: 83, loss: 0.6401998938800638, acc: 0.7455541280681588, prc: 0.8823034003579324, rec: 0.5667049834336331, f1: 0.6901350461133069\n",
            "epoch: 84, loss: 0.6398680354794486, acc: 0.7468388667252688, prc: 0.8825316986272661, rec: 0.5694773142200285, f1: 0.6922571099786289\n",
            "epoch: 85, loss: 0.6395378435819946, acc: 0.7478869429981743, prc: 0.8825125208681135, rec: 0.5719115558861316, f1: 0.6940466910105445\n",
            "epoch: 86, loss: 0.6392091721627784, acc: 0.7490702549191967, prc: 0.8827012987012987, rec: 0.5744810332003516, f1: 0.6959941017449005\n",
            "epoch: 87, loss: 0.6388818616939183, acc: 0.7499492866319561, prc: 0.8827793310551931, rec: 0.5764419500980459, f1: 0.6974556164607707\n",
            "epoch: 88, loss: 0.6385557586130532, acc: 0.750726891608628, prc: 0.8829787234042553, rec: 0.578064777875448, f1: 0.6987045891054718\n",
            "epoch: 89, loss: 0.638230720064951, acc: 0.7518763946176212, prc: 0.8833093229059478, rec: 0.5804314017174927, f1: 0.7005345411515079\n",
            "epoch: 90, loss: 0.6379065835995854, acc: 0.7533977956589357, prc: 0.8836899764513156, rec: 0.5836094394482385, f1: 0.7029646522234893\n",
            "================validation================\n",
            "epoch: 90, loss: 0.6275129456648373, acc: 0.7927683727195814, prc: 0.04783111296405086, rec: 0.9221775666788454, f1: 0.09094512304976038\n",
            "==========================================\n",
            "epoch: 91, loss: 0.6375831972989172, acc: 0.7546149164919873, prc: 0.8834911905489358, rec: 0.5865846237068091, f1: 0.7050552665799741\n",
            "epoch: 92, loss: 0.6372604076392585, acc: 0.7560348907972142, prc: 0.8835984196130078, rec: 0.589762661437555, f1: 0.7073803730738036\n",
            "epoch: 93, loss: 0.6369380668571771, acc: 0.7573534383663534, prc: 0.8839790153349475, rec: 0.5924673743998918, f1: 0.7094449617424395\n",
            "epoch: 94, loss: 0.636616004032088, acc: 0.7589086483196971, prc: 0.8841292134831461, rec: 0.5959158834268713, f1: 0.7119602536656299\n",
            "epoch: 95, loss: 0.6362940710213222, acc: 0.7606329028331869, prc: 0.8843354272609433, rec: 0.599702481574143, f1: 0.7147231847852366\n",
            "epoch: 96, loss: 0.635972105375844, acc: 0.7618838325782676, prc: 0.8844550327575939, rec: 0.6024748123605382, f1: 0.7167276676185497\n",
            "epoch: 97, loss: 0.6356499559164865, acc: 0.7629995266752316, prc: 0.8846039750815782, rec: 0.6049090540266414, f1: 0.7184965063047146\n",
            "epoch: 98, loss: 0.6353274558013305, acc: 0.7640814118601663, prc: 0.8847404196630874, rec: 0.6072756778686862, f1: 0.7202085004009623\n",
            "epoch: 99, loss: 0.6350044543418965, acc: 0.7653323416052471, prc: 0.8849323131253679, rec: 0.6099803908310231, f1: 0.7221710763319057\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0y-AiF-g9RMQ"
      },
      "source": [
        "### Show the performance on testing set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67JFfFqA3jyj",
        "outputId": "62ac325d-781e-4d03-ddf1-1b4a279d6c1c"
      },
      "source": [
        "model_test = simpleNN()\n",
        "model_test.load_state_dict(torch.load('/content/drive/My Drive/fintech-introduction/term-project/simpleNN_s2.pkl'))\n",
        "model_test = model_test.to(device)\n",
        "model_test.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "simpleNN(\n",
              "  (conv): Sequential(\n",
              "    (0): BatchNorm1d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (1): Linear(in_features=23, out_features=10, bias=True)\n",
              "    (2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Sigmoid()\n",
              "    (4): Linear(in_features=10, out_features=5, bias=True)\n",
              "    (5): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): Sigmoid()\n",
              "    (7): Linear(in_features=5, out_features=2, bias=True)\n",
              "    (8): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFD8MBAb9UXh"
      },
      "source": [
        "y_pred = model_test(x_test)\n",
        "y_scalar = []\n",
        "for d in y_pred:\n",
        "  if d[0]>d[1]:\n",
        "    y_scalar.append(0)\n",
        "  else:\n",
        "    y_scalar.append(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Pj7IGnB9XH9",
        "outputId": "4dc99c6e-caa1-41ed-d5e0-d083f89a5dfa"
      },
      "source": [
        "y_target = y_test\n",
        "cm = confusion_matrix(y_target, y_scalar)\n",
        "# row: actually, column: predict, the smaller class will be the target for counting the following indexies\n",
        "print(cm)\n",
        "\n",
        "# these libraries will automatically take the fewer class to evaluate the performance\n",
        "print('accuracy_score: ', accuracy_score(y_target, y_scalar))\n",
        "print(\"precision_score\", precision_score(y_target, y_scalar))\n",
        "print(\"recall_score\",    recall_score(y_target, y_scalar))\n",
        "print(\"f1_score\",        f1_score(y_target, y_scalar))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[278667  22862]\n",
            " [  1004   1825]]\n",
            "accuracy_score:  0.9215857641330275\n",
            "precision_score 0.07392554785919715\n",
            "recall_score 0.6451042771297278\n",
            "f1_score 0.1326500944904783\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRmjtPha9Xuj",
        "outputId": "b4a1bb3c-87b2-4e91-a72f-14561b546f5d"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "simpleNN(\n",
            "  (conv): Sequential(\n",
            "    (0): BatchNorm1d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): Linear(in_features=23, out_features=10, bias=True)\n",
            "    (2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): Sigmoid()\n",
            "    (4): Linear(in_features=10, out_features=5, bias=True)\n",
            "    (5): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): Sigmoid()\n",
            "    (7): Linear(in_features=5, out_features=2, bias=True)\n",
            "    (8): Sigmoid()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8qPJrOSEOWz"
      },
      "source": [
        "# Data Processing scenario 3\n",
        "- Base on scenerio 1\n",
        "- Convert locdt and loctm\n",
        "- 64%(0.8 * 0.8) training data\n",
        "- 16%(0.8 * 0.2) to validate\n",
        "- 20% to test\n",
        "- f1 : 0.17"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "OwfviRZHEUss",
        "outputId": "91f66aff-ddc4-4c6d-ae93-5a1b2e887365"
      },
      "source": [
        "import pandas as pd\n",
        "with open('/content/drive/My Drive/fintech-introduction/term-project/train_locdt_loctm_converted.csv', 'r') as f:\n",
        "  df = pd.read_csv(f)\n",
        "  # df = df.set_index('txkey')\n",
        "\n",
        "\n",
        "# print(df_X)\n",
        "# print(df_y)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>txkey</th>\n",
              "      <th>acqic</th>\n",
              "      <th>bacno</th>\n",
              "      <th>cano</th>\n",
              "      <th>conam</th>\n",
              "      <th>contp</th>\n",
              "      <th>csmcu</th>\n",
              "      <th>ecfg</th>\n",
              "      <th>etymd</th>\n",
              "      <th>flbmk</th>\n",
              "      <th>flg_3dsmk</th>\n",
              "      <th>fraud_ind</th>\n",
              "      <th>hcefg</th>\n",
              "      <th>insfg</th>\n",
              "      <th>iterm</th>\n",
              "      <th>locdt</th>\n",
              "      <th>mcc</th>\n",
              "      <th>mchno</th>\n",
              "      <th>ovrlt</th>\n",
              "      <th>scity</th>\n",
              "      <th>stocn</th>\n",
              "      <th>stscd</th>\n",
              "      <th>hh</th>\n",
              "      <th>mm</th>\n",
              "      <th>ss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1547337</td>\n",
              "      <td>6767</td>\n",
              "      <td>137279</td>\n",
              "      <td>176279</td>\n",
              "      <td>785.96</td>\n",
              "      <td>5</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>191</td>\n",
              "      <td>16615</td>\n",
              "      <td>0</td>\n",
              "      <td>5817</td>\n",
              "      <td>102</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>361558</td>\n",
              "      <td>6032</td>\n",
              "      <td>95126</td>\n",
              "      <td>90258</td>\n",
              "      <td>325.94</td>\n",
              "      <td>5</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>251</td>\n",
              "      <td>78641</td>\n",
              "      <td>0</td>\n",
              "      <td>5817</td>\n",
              "      <td>102</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>29</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1833662</td>\n",
              "      <td>6215</td>\n",
              "      <td>104992</td>\n",
              "      <td>168046</td>\n",
              "      <td>288.05</td>\n",
              "      <td>5</td>\n",
              "      <td>62</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>380</td>\n",
              "      <td>54238</td>\n",
              "      <td>0</td>\n",
              "      <td>6580</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1119486</td>\n",
              "      <td>6717</td>\n",
              "      <td>158233</td>\n",
              "      <td>33494</td>\n",
              "      <td>796.90</td>\n",
              "      <td>5</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>304</td>\n",
              "      <td>33656</td>\n",
              "      <td>0</td>\n",
              "      <td>5800</td>\n",
              "      <td>102</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>33</td>\n",
              "      <td>53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1047761</td>\n",
              "      <td>5975</td>\n",
              "      <td>78764</td>\n",
              "      <td>162106</td>\n",
              "      <td>800.02</td>\n",
              "      <td>5</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>263</td>\n",
              "      <td>93792</td>\n",
              "      <td>0</td>\n",
              "      <td>5817</td>\n",
              "      <td>102</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>14</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1521782</th>\n",
              "      <td>1927172</td>\n",
              "      <td>6618</td>\n",
              "      <td>65727</td>\n",
              "      <td>181927</td>\n",
              "      <td>228.54</td>\n",
              "      <td>5</td>\n",
              "      <td>62</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>192</td>\n",
              "      <td>65472</td>\n",
              "      <td>0</td>\n",
              "      <td>6593</td>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>54</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1521783</th>\n",
              "      <td>239570</td>\n",
              "      <td>6769</td>\n",
              "      <td>43220</td>\n",
              "      <td>18630</td>\n",
              "      <td>939.74</td>\n",
              "      <td>5</td>\n",
              "      <td>62</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>373</td>\n",
              "      <td>79200</td>\n",
              "      <td>0</td>\n",
              "      <td>5817</td>\n",
              "      <td>102</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>42</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1521784</th>\n",
              "      <td>1459534</td>\n",
              "      <td>6767</td>\n",
              "      <td>18611</td>\n",
              "      <td>35515</td>\n",
              "      <td>383.76</td>\n",
              "      <td>5</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>247</td>\n",
              "      <td>6484</td>\n",
              "      <td>0</td>\n",
              "      <td>5817</td>\n",
              "      <td>102</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1521785</th>\n",
              "      <td>580748</td>\n",
              "      <td>6881</td>\n",
              "      <td>7613</td>\n",
              "      <td>38076</td>\n",
              "      <td>513.80</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>457</td>\n",
              "      <td>59333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>102</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>2</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1521786</th>\n",
              "      <td>785207</td>\n",
              "      <td>3210</td>\n",
              "      <td>77247</td>\n",
              "      <td>151506</td>\n",
              "      <td>391.88</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>294</td>\n",
              "      <td>43529</td>\n",
              "      <td>0</td>\n",
              "      <td>2249</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>54</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1521787 rows × 25 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           txkey  acqic   bacno    cano   conam  ...  stocn  stscd  hh  mm  ss\n",
              "0        1547337   6767  137279  176279  785.96  ...    102      0   7   6   2\n",
              "1         361558   6032   95126   90258  325.94  ...    102      0  19  29  20\n",
              "2        1833662   6215  104992  168046  288.05  ...     38      0  16   1  24\n",
              "3        1119486   6717  158233   33494  796.90  ...    102      0  15  33  53\n",
              "4        1047761   5975   78764  162106  800.02  ...    102      0  19  14  48\n",
              "...          ...    ...     ...     ...     ...  ...    ...    ...  ..  ..  ..\n",
              "1521782  1927172   6618   65727  181927  228.54  ...     75      0  16  54  27\n",
              "1521783   239570   6769   43220   18630  939.74  ...    102      0  12  42  32\n",
              "1521784  1459534   6767   18611   35515  383.76  ...    102      0  14   1  37\n",
              "1521785   580748   6881    7613   38076  513.80  ...    102      0  18   2  43\n",
              "1521786   785207   3210   77247  151506  391.88  ...      6      0  15  54  30\n",
              "\n",
              "[1521787 rows x 25 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Op_1zcdBEYID",
        "outputId": "68654e38-ab20-4c24-a665-21117f42b5bb"
      },
      "source": [
        "df_y = df['fraud_ind']\n",
        "df_x = df.drop(['fraud_ind', 'txkey'], 1)\n",
        "df_x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>acqic</th>\n",
              "      <th>bacno</th>\n",
              "      <th>cano</th>\n",
              "      <th>conam</th>\n",
              "      <th>contp</th>\n",
              "      <th>csmcu</th>\n",
              "      <th>ecfg</th>\n",
              "      <th>etymd</th>\n",
              "      <th>flbmk</th>\n",
              "      <th>flg_3dsmk</th>\n",
              "      <th>hcefg</th>\n",
              "      <th>insfg</th>\n",
              "      <th>iterm</th>\n",
              "      <th>locdt</th>\n",
              "      <th>mcc</th>\n",
              "      <th>mchno</th>\n",
              "      <th>ovrlt</th>\n",
              "      <th>scity</th>\n",
              "      <th>stocn</th>\n",
              "      <th>stscd</th>\n",
              "      <th>hh</th>\n",
              "      <th>mm</th>\n",
              "      <th>ss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6767</td>\n",
              "      <td>137279</td>\n",
              "      <td>176279</td>\n",
              "      <td>785.96</td>\n",
              "      <td>5</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>191</td>\n",
              "      <td>16615</td>\n",
              "      <td>0</td>\n",
              "      <td>5817</td>\n",
              "      <td>102</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6032</td>\n",
              "      <td>95126</td>\n",
              "      <td>90258</td>\n",
              "      <td>325.94</td>\n",
              "      <td>5</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>251</td>\n",
              "      <td>78641</td>\n",
              "      <td>0</td>\n",
              "      <td>5817</td>\n",
              "      <td>102</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>29</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6215</td>\n",
              "      <td>104992</td>\n",
              "      <td>168046</td>\n",
              "      <td>288.05</td>\n",
              "      <td>5</td>\n",
              "      <td>62</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>380</td>\n",
              "      <td>54238</td>\n",
              "      <td>0</td>\n",
              "      <td>6580</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6717</td>\n",
              "      <td>158233</td>\n",
              "      <td>33494</td>\n",
              "      <td>796.90</td>\n",
              "      <td>5</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>304</td>\n",
              "      <td>33656</td>\n",
              "      <td>0</td>\n",
              "      <td>5800</td>\n",
              "      <td>102</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>33</td>\n",
              "      <td>53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5975</td>\n",
              "      <td>78764</td>\n",
              "      <td>162106</td>\n",
              "      <td>800.02</td>\n",
              "      <td>5</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>263</td>\n",
              "      <td>93792</td>\n",
              "      <td>0</td>\n",
              "      <td>5817</td>\n",
              "      <td>102</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>14</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1521782</th>\n",
              "      <td>6618</td>\n",
              "      <td>65727</td>\n",
              "      <td>181927</td>\n",
              "      <td>228.54</td>\n",
              "      <td>5</td>\n",
              "      <td>62</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>192</td>\n",
              "      <td>65472</td>\n",
              "      <td>0</td>\n",
              "      <td>6593</td>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>54</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1521783</th>\n",
              "      <td>6769</td>\n",
              "      <td>43220</td>\n",
              "      <td>18630</td>\n",
              "      <td>939.74</td>\n",
              "      <td>5</td>\n",
              "      <td>62</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>373</td>\n",
              "      <td>79200</td>\n",
              "      <td>0</td>\n",
              "      <td>5817</td>\n",
              "      <td>102</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>42</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1521784</th>\n",
              "      <td>6767</td>\n",
              "      <td>18611</td>\n",
              "      <td>35515</td>\n",
              "      <td>383.76</td>\n",
              "      <td>5</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>247</td>\n",
              "      <td>6484</td>\n",
              "      <td>0</td>\n",
              "      <td>5817</td>\n",
              "      <td>102</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1521785</th>\n",
              "      <td>6881</td>\n",
              "      <td>7613</td>\n",
              "      <td>38076</td>\n",
              "      <td>513.80</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>457</td>\n",
              "      <td>59333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>102</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>2</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1521786</th>\n",
              "      <td>3210</td>\n",
              "      <td>77247</td>\n",
              "      <td>151506</td>\n",
              "      <td>391.88</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>294</td>\n",
              "      <td>43529</td>\n",
              "      <td>0</td>\n",
              "      <td>2249</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>54</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1521787 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         acqic   bacno    cano   conam  contp  ...  stocn  stscd  hh  mm  ss\n",
              "0         6767  137279  176279  785.96      5  ...    102      0   7   6   2\n",
              "1         6032   95126   90258  325.94      5  ...    102      0  19  29  20\n",
              "2         6215  104992  168046  288.05      5  ...     38      0  16   1  24\n",
              "3         6717  158233   33494  796.90      5  ...    102      0  15  33  53\n",
              "4         5975   78764  162106  800.02      5  ...    102      0  19  14  48\n",
              "...        ...     ...     ...     ...    ...  ...    ...    ...  ..  ..  ..\n",
              "1521782   6618   65727  181927  228.54      5  ...     75      0  16  54  27\n",
              "1521783   6769   43220   18630  939.74      5  ...    102      0  12  42  32\n",
              "1521784   6767   18611   35515  383.76      5  ...    102      0  14   1  37\n",
              "1521785   6881    7613   38076  513.80      5  ...    102      0  18   2  43\n",
              "1521786   3210   77247  151506  391.88      5  ...      6      0  15  54  30\n",
              "\n",
              "[1521787 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaBosMTsEbtS",
        "outputId": "0bde5693-0199-42a8-d8f2-698035715992"
      },
      "source": [
        "# split train+val and test\n",
        "df_x_data, df_x_test = train_test_split(df_x, test_size=0.2, shuffle=False)\n",
        "df_y_data = df_y.loc[df_x_data.index]\n",
        "df_y_test = df_y.loc[df_x_test.index]\n",
        "\n",
        "# print(df_x_data)\n",
        "# print(df_x_test)\n",
        "# print(df_y_data)\n",
        "# print(df_y_test)\n",
        "\n",
        "#split train and val\n",
        "df_x_train, df_x_val = train_test_split(df_x_data, test_size=0.2, shuffle=False)\n",
        "df_y_train = df_y_data.loc[df_x_train.index]\n",
        "df_y_val = df_y_data.loc[df_x_val.index]\n",
        "\n",
        "\n",
        "print('df_x_train:')\n",
        "print(df_x_train)\n",
        "print('df_x_val:')\n",
        "print(df_x_val)\n",
        "print('df_x_test:')\n",
        "print(df_x_test)\n",
        "print('df_y_train:')\n",
        "print(df_y_train)\n",
        "print('df_y_val:')\n",
        "print(df_y_val)\n",
        "print('df_y_test:')\n",
        "print(df_y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "df_x_train:\n",
            "        acqic   bacno    cano    conam  contp  ...  stocn  stscd  hh  mm  ss\n",
            "0        6767  137279  176279   785.96      5  ...    102      0   7   6   2\n",
            "1        6032   95126   90258   325.94      5  ...    102      0  19  29  20\n",
            "2        6215  104992  168046   288.05      5  ...     38      0  16   1  24\n",
            "3        6717  158233   33494   796.90      5  ...    102      0  15  33  53\n",
            "4        5975   78764  162106   800.02      5  ...    102      0  19  14  48\n",
            "...       ...     ...     ...      ...    ...  ...    ...    ...  ..  ..  ..\n",
            "973938   6777   61498   91553  1154.25      5  ...    102      0  19  30  19\n",
            "973939   6625   87717   81548   366.38      5  ...    102      0  16  36  56\n",
            "973940   6769  110892  124186   352.55      5  ...    102      0  20  29   1\n",
            "973941   6215   60807   10755   168.20      5  ...     38      0  16  29  58\n",
            "973942   6769  121100  190558   834.05      5  ...    102      0  18  20  33\n",
            "\n",
            "[973943 rows x 23 columns]\n",
            "df_x_val:\n",
            "         acqic   bacno    cano    conam  contp  ...  stocn  stscd  hh  mm  ss\n",
            "973943    6769   63692  126110   370.84      5  ...    102      0  20  46  20\n",
            "973944    5975   37219   66575  1012.88      5  ...    102      0  20   6   2\n",
            "973945    6231  147317  191373  1193.97      5  ...    102      0  15  10  17\n",
            "973946    6581   80877  148095   981.75      5  ...    102      0  13  59  41\n",
            "973947    6189    6375  151060   686.70      5  ...    102      0  18   5  52\n",
            "...        ...     ...     ...      ...    ...  ...    ...    ...  ..  ..  ..\n",
            "1217424   5975   43783  135161   726.90      5  ...    102      0  19  42  59\n",
            "1217425   6189  156962  130978   747.35      5  ...    102      0  15  20  41\n",
            "1217426   6189   55833   73570   778.01      2  ...    102      0   9  25  14\n",
            "1217427   6189    8720   55314  1145.74      5  ...    102      0  16  21  52\n",
            "1217428   6189   24129  129395   590.50      2  ...    102      0  13  45  39\n",
            "\n",
            "[243486 rows x 23 columns]\n",
            "df_x_test:\n",
            "         acqic   bacno    cano    conam  contp  ...  stocn  stscd  hh  mm  ss\n",
            "1217429   6769   66594  102307  1100.42      6  ...    102      0   9   6   4\n",
            "1217430   6769   41842  147528  1647.46      5  ...    102      0  17  19  39\n",
            "1217431   6769   49879   62792  2071.74      5  ...    102      0  20  31  48\n",
            "1217432   6779  133873  211554  1485.11      5  ...    102      0  17  56   8\n",
            "1217433   6716   69469   67755   625.98      5  ...    102      0  18  37   5\n",
            "...        ...     ...     ...      ...    ...  ...    ...    ...  ..  ..  ..\n",
            "1521782   6618   65727  181927   228.54      5  ...     75      0  16  54  27\n",
            "1521783   6769   43220   18630   939.74      5  ...    102      0  12  42  32\n",
            "1521784   6767   18611   35515   383.76      5  ...    102      0  14   1  37\n",
            "1521785   6881    7613   38076   513.80      5  ...    102      0  18   2  43\n",
            "1521786   3210   77247  151506   391.88      5  ...      6      0  15  54  30\n",
            "\n",
            "[304358 rows x 23 columns]\n",
            "df_y_train:\n",
            "0         0\n",
            "1         0\n",
            "2         0\n",
            "3         0\n",
            "4         0\n",
            "         ..\n",
            "973938    0\n",
            "973939    0\n",
            "973940    0\n",
            "973941    0\n",
            "973942    0\n",
            "Name: fraud_ind, Length: 973943, dtype: int64\n",
            "df_y_val:\n",
            "973943     0\n",
            "973944     0\n",
            "973945     0\n",
            "973946     0\n",
            "973947     0\n",
            "          ..\n",
            "1217424    0\n",
            "1217425    0\n",
            "1217426    0\n",
            "1217427    0\n",
            "1217428    0\n",
            "Name: fraud_ind, Length: 243486, dtype: int64\n",
            "df_y_test:\n",
            "1217429    0\n",
            "1217430    0\n",
            "1217431    0\n",
            "1217432    0\n",
            "1217433    0\n",
            "          ..\n",
            "1521782    0\n",
            "1521783    0\n",
            "1521784    0\n",
            "1521785    0\n",
            "1521786    0\n",
            "Name: fraud_ind, Length: 304358, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l7JMI2FEkre"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import math\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "lr = 1e-2\n",
        "batch_size = 973943\n",
        "batch_num = math.ceil(df_x_train.shape[0] / batch_size)\n",
        "max_epoch = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEPXkeLFEobb"
      },
      "source": [
        "x_train = torch.from_numpy(df_x_train.values).to(device)\n",
        "y_train = torch.from_numpy(df_y_train.values).to(device)\n",
        "loader = DataLoader(TensorDataset(x_train, y_train), batch_size=batch_size, shuffle=True)\n",
        "\n",
        "x_val = torch.from_numpy(df_x_val.values).to(device)\n",
        "y_val = torch.from_numpy(df_y_val.values).to(device)\n",
        "\n",
        "x_test = torch.from_numpy(df_x_test.values).to(device)\n",
        "y_test = torch.from_numpy(df_y_test.values).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ai_bTOXErTy"
      },
      "source": [
        "n = x_train.shape[1]\n",
        "class simpleNN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(simpleNN, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            # nn.BatchNorm1d(n),\n",
        "            nn.Linear(n, 10),\n",
        "            nn.BatchNorm1d(10),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(10,5),\n",
        "            nn.BatchNorm1d(5),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(5,2),\n",
        "            # nn.BatchNorm1d(2),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.y_pred = self.conv(x.float())\n",
        "        return self.y_pred\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss().to(device)\n",
        "model = simpleNN()\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpCdxlUKE3uE"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qY6gv3S9E20y",
        "outputId": "d32c222c-7a01-4487-a04d-f60798b9f44b"
      },
      "source": [
        "model.train()\n",
        "val_f1_max = 0\n",
        "for epoch in range(max_epoch):\n",
        "  e_loss = 0\n",
        "  e_acc = 0\n",
        "  e_prc = 0\n",
        "  e_rec = 0\n",
        "  e_f1 = 0\n",
        "\n",
        "  for x_batch, y_batch in loader:\n",
        "    current_size = y_batch.shape[0]\n",
        "    optimizer.zero_grad()\n",
        "    y_pred = model(x_batch)\n",
        "    y_scalar = []\n",
        "    for d in y_pred:\n",
        "      if d[0]>d[1]:\n",
        "        y_scalar.append(0)\n",
        "      else:\n",
        "        y_scalar.append(1)\n",
        "    \n",
        "    loss = loss_func(y_pred.double(), y_batch.flatten().long()).to(device)\n",
        "    e_loss += loss.item()\n",
        "    # loss = loss.float()\n",
        "\n",
        "    e_acc += accuracy_score(y_batch, y_scalar)\n",
        "    e_prc += precision_score(y_batch, y_scalar)\n",
        "    e_rec += recall_score(y_batch, y_scalar)\n",
        "    e_f1 += f1_score(y_batch, y_scalar)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  \n",
        "  e_acc = (e_acc / batch_num)\n",
        "  e_loss = (e_loss / batch_num)\n",
        "  e_prc = (e_prc / batch_num)\n",
        "  e_rec = (e_rec / batch_num)\n",
        "  e_f1 = (e_f1 / batch_num)\n",
        "  print('epoch: {}, loss: {}, acc: {}, prc: {}, rec: {}, f1: {}'.format(epoch, e_loss, e_acc, e_prc, e_rec, e_f1))\n",
        "\n",
        "  if epoch%10 == 0:\n",
        "    y_pred = model(x_val)\n",
        "    y_scalar = []\n",
        "    for d in y_pred:\n",
        "      if d[0]>d[1]:\n",
        "        y_scalar.append(0)\n",
        "      else:\n",
        "        y_scalar.append(1)\n",
        "    \n",
        "\n",
        "    val_loss = loss_func(y_pred.double(), y_val.flatten().long()).to(device)\n",
        "    val_acc = accuracy_score(y_val, y_scalar)\n",
        "    val_prc = precision_score(y_val, y_scalar)\n",
        "    val_rec = recall_score(y_val, y_scalar)\n",
        "    val_f1 = f1_score(y_val, y_scalar)\n",
        "    print(\"================validation================\")\n",
        "    print('epoch: {}, loss: {}, acc: {}, prc: {}, rec: {}, f1: {}'.format(epoch, val_loss, val_acc, val_prc, val_rec, val_f1))\n",
        "    if val_f1 > val_f1_max:\n",
        "        val_f1_max = val_f1\n",
        "        torch.save(model.state_dict(), '/content/drive/My Drive/fintech-introduction/term-project/simpleNN_s3.pkl')\n",
        "        print('update_file')\n",
        "    print('==========================================')\n",
        "\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, loss: 0.685023317961503, acc: 0.7125191104612898, prc: 0.030689134043313762, rec: 0.5863141524105754, f1: 0.05832537365638411\n",
            "================validation================\n",
            "epoch: 0, loss: 0.6841819105464264, acc: 0.7339231003014547, prc: 0.023923151288228705, rec: 0.5696017537449762, f1: 0.045917766258246936\n",
            "update_file\n",
            "==========================================\n",
            "epoch: 1, loss: 0.6840526646294234, acc: 0.7342072380005812, prc: 0.032747028914481745, rec: 0.5783352491716817, f1: 0.06198432455348892\n",
            "epoch: 2, loss: 0.683083989615869, acc: 0.754974367083084, prc: 0.03506359716533601, rec: 0.5707620528771384, f1: 0.06606841654175945\n",
            "epoch: 3, loss: 0.6821173480660118, acc: 0.774765052985647, prc: 0.037568321451014255, rec: 0.5619041179254851, f1: 0.07042790674023035\n",
            "epoch: 4, loss: 0.6811528028907942, acc: 0.793441710654525, prc: 0.04050449419920421, rec: 0.5554804246399351, f1: 0.07550343280975709\n",
            "epoch: 5, loss: 0.680190415701694, acc: 0.810806176542159, prc: 0.04353611040783456, rec: 0.546487254040165, f1: 0.0806474145328996\n",
            "epoch: 6, loss: 0.6792302070688302, acc: 0.8269980892105595, prc: 0.04693238694311637, rec: 0.5383054973290959, f1: 0.08633741107062294\n",
            "epoch: 7, loss: 0.6782721555988475, acc: 0.8421457929262801, prc: 0.05070101919395727, rec: 0.5301237406180269, f1: 0.09255051026732222\n",
            "epoch: 8, loss: 0.6773162010135636, acc: 0.8560182680095242, prc: 0.05486753298368381, rec: 0.5227533977956589, f1: 0.09931146108984404\n",
            "epoch: 9, loss: 0.6763622476578875, acc: 0.8684892237020031, prc: 0.05918057663125948, rec: 0.5142335519642978, f1: 0.106145407344341\n",
            "epoch: 10, loss: 0.6754101853353304, acc: 0.8799477998199073, prc: 0.0639467864370309, rec: 0.5063898843735208, f1: 0.11355400221376478\n",
            "================validation================\n",
            "epoch: 10, loss: 0.6745422090180316, acc: 0.892852155770763, prc: 0.05199140511088942, rec: 0.49506759225429303, f1: 0.09410048960033335\n",
            "update_file\n",
            "==========================================\n",
            "epoch: 11, loss: 0.6744599103558468, acc: 0.8901537358962486, prc: 0.06916211037898967, rec: 0.5003718980323213, f1: 0.12152663732510019\n",
            "epoch: 12, loss: 0.6735113331628021, acc: 0.8990505604537432, prc: 0.07428699569853016, rec: 0.49279870173777807, f1: 0.129111120953098\n",
            "epoch: 13, loss: 0.6725643806844317, acc: 0.9070335738333762, prc: 0.07980652962515115, rec: 0.4864426262762864, f1: 0.13711737124995235\n",
            "epoch: 14, loss: 0.6716189885006375, acc: 0.9140298764917454, prc: 0.0853073156647378, rec: 0.479477990398269, f1: 0.1448443500285971\n",
            "epoch: 15, loss: 0.6706751178081211, acc: 0.9199871039680967, prc: 0.09020340875163882, rec: 0.4698762593819731, f1: 0.15135146908283056\n",
            "epoch: 16, loss: 0.6697327329868932, acc: 0.9253323859815205, prc: 0.09569404703747644, rec: 0.46358780174453984, f1: 0.15864127542402295\n",
            "epoch: 17, loss: 0.6687918148708215, acc: 0.930097551910122, prc: 0.10121524140201742, rec: 0.45729934410710665, f1: 0.16574558555025917\n",
            "epoch: 18, loss: 0.6678523600986992, acc: 0.9341368026670965, prc: 0.10664647752629901, rec: 0.45243086077490025, f1: 0.17260637954829805\n",
            "epoch: 19, loss: 0.6669143768998208, acc: 0.9376041513723082, prc: 0.11146975816673145, rec: 0.4460071674893502, f1: 0.17836186149644415\n",
            "epoch: 20, loss: 0.6659778742224112, acc: 0.9407378049844806, prc: 0.11623250075986484, rec: 0.4395834742038001, f1: 0.18385180995475112\n",
            "================validation================\n",
            "epoch: 20, loss: 0.6650727950136319, acc: 0.9465020576131687, prc: 0.09309499327691212, rec: 0.4300328827183047, f1: 0.1530559167750325\n",
            "update_file\n",
            "==========================================\n",
            "epoch: 21, loss: 0.6650428678529733, acc: 0.9433786166130872, prc: 0.12088304368248004, rec: 0.43505307999188586, f1: 0.18919634192960275\n",
            "epoch: 22, loss: 0.6641093732966183, acc: 0.9456251546548412, prc: 0.12491892848017924, rec: 0.42977888971532896, f1: 0.19357393025734734\n",
            "epoch: 23, loss: 0.6631774085524981, acc: 0.9475349173411586, prc: 0.12868917840999733, rec: 0.42545134897558995, f1: 0.197606859081059\n",
            "epoch: 24, loss: 0.6622470038886731, acc: 0.9491356270336149, prc: 0.13179198101212172, rec: 0.4205152478193252, f1: 0.2006873517595237\n",
            "epoch: 25, loss: 0.6613181773874689, acc: 0.9505330394078504, prc: 0.13455771293478974, rec: 0.4156467644871188, f1: 0.20330070115094587\n",
            "epoch: 26, loss: 0.660390957384129, acc: 0.9516778702655083, prc: 0.13675040518638573, rec: 0.41077828115491244, f1: 0.20519142755813757\n",
            "epoch: 27, loss: 0.659465367195508, acc: 0.9527498015797639, prc: 0.13904299583911234, rec: 0.4067212117114071, f1: 0.20723871212251718\n",
            "epoch: 28, loss: 0.6585414446830848, acc: 0.9536800408237444, prc: 0.141085124514724, rec: 0.4030022313881939, f1: 0.20900180597198115\n",
            "epoch: 29, loss: 0.6576192049531466, acc: 0.9544757752763765, prc: 0.14272241433511473, rec: 0.39908039759280545, f1: 0.21025257383064372\n",
            "epoch: 30, loss: 0.6566986754983665, acc: 0.9551996369397387, prc: 0.14444554016074157, rec: 0.3961728311582933, f1: 0.21170349225849577\n",
            "================validation================\n",
            "epoch: 30, loss: 0.6557540290186451, acc: 0.9584370353942321, prc: 0.11211516234107387, rec: 0.3898428936792108, f1: 0.17414721723518853\n",
            "update_file\n",
            "==========================================\n",
            "epoch: 31, loss: 0.6557798740379149, acc: 0.9560015319171656, prc: 0.14644593947640286, rec: 0.3929947934275475, f1: 0.21337836845583377\n",
            "epoch: 32, loss: 0.6548628086459418, acc: 0.9567315541053224, prc: 0.14825102880658436, rec: 0.38974913787274323, f1: 0.2147981143676983\n",
            "epoch: 33, loss: 0.6539474777515737, acc: 0.9574205061281821, prc: 0.14986483294401723, rec: 0.38609777537358847, f1: 0.21591983361694086\n",
            "epoch: 34, loss: 0.653033888866014, acc: 0.9581032976262471, prc: 0.1517642019596295, rec: 0.3833254445871932, f1: 0.21744050016301328\n",
            "epoch: 35, loss: 0.652122018110994, acc: 0.9587573400086042, prc: 0.15356684594174014, rec: 0.3803502603286226, f1: 0.21879497452254076\n",
            "epoch: 36, loss: 0.6512118454998375, acc: 0.9594257569488153, prc: 0.15517626059794734, rec: 0.3762255730610589, f1: 0.21972554052719911\n",
            "epoch: 37, loss: 0.6503033457206921, acc: 0.9601352440543235, prc: 0.15723126942931295, rec: 0.3727770640340794, f1: 0.22117467704405036\n",
            "epoch: 38, loss: 0.6493964751859713, acc: 0.9608868280792613, prc: 0.15937326434564003, rec: 0.36865237676651563, f1: 0.2225396954977754\n",
            "epoch: 39, loss: 0.6484911917695442, acc: 0.9616743484988342, prc: 0.16179471788715485, rec: 0.3645276894989519, f1: 0.22411606975825726\n",
            "epoch: 40, loss: 0.647587448247671, acc: 0.9625347684618094, prc: 0.1643153270218427, rec: 0.3591182635742782, f1: 0.22546751289507758\n",
            "================validation================\n",
            "epoch: 40, loss: 0.6466021490457293, acc: 0.9648645096638, prc: 0.12406306539157405, rec: 0.35074899525027403, f1: 0.18329355608591885\n",
            "update_file\n",
            "==========================================\n",
            "epoch: 41, loss: 0.6466852134669862, acc: 0.9634834892801735, prc: 0.1676690767163606, rec: 0.35438501589018867, f1: 0.227636979607792\n",
            "epoch: 42, loss: 0.6457844435928182, acc: 0.9644147552782864, prc: 0.1702240663900415, rec: 0.346744201771587, f1: 0.22834750857193747\n",
            "epoch: 43, loss: 0.6448851197328048, acc: 0.9654517769520393, prc: 0.1723478925605476, rec: 0.33538440732977215, f1: 0.22769004774146162\n",
            "epoch: 44, loss: 0.6439872452996898, acc: 0.9666417849915242, prc: 0.17214936652589463, rec: 0.3142200283994861, f1: 0.22243496158724838\n",
            "epoch: 45, loss: 0.6430908326074014, acc: 0.9679940201839328, prc: 0.17018963642952048, rec: 0.28582054229494896, f1: 0.21334477363347296\n",
            "epoch: 46, loss: 0.6421959457009864, acc: 0.9694232619362735, prc: 0.16386385039687879, rec: 0.24707552910947325, f1: 0.1970448662640207\n",
            "epoch: 47, loss: 0.6413026823375046, acc: 0.9710301321535244, prc: 0.1578840077464071, rec: 0.20948001893299073, f1: 0.18005870215919326\n",
            "epoch: 48, loss: 0.6404111849401312, acc: 0.9728002562778314, prc: 0.14985038898862957, rec: 0.16931503144228818, f1: 0.15898917425950027\n",
            "epoch: 49, loss: 0.6395216416791428, acc: 0.9747295272926649, prc: 0.14560935132404934, rec: 0.1364527689498952, f1: 0.1408824350740017\n",
            "epoch: 50, loss: 0.6386342947730181, acc: 0.9765900057806257, prc: 0.14258945302043366, rec: 0.10805328284535803, f1: 0.12294199107555011\n",
            "================validation================\n",
            "epoch: 50, loss: 0.63760322983764, acc: 0.9808366805483683, prc: 0.08693790149892934, rec: 0.0741687979539642, f1: 0.08004731861198738\n",
            "==========================================\n",
            "epoch: 51, loss: 0.6377494228633676, acc: 0.9783262470185626, prc: 0.14502359020444844, rec: 0.08729461085942254, f1: 0.10898653497108607\n",
            "epoch: 52, loss: 0.636867337123832, acc: 0.9797719168370222, prc: 0.15123544447600112, rec: 0.07201298262221922, f1: 0.09756767898859421\n",
            "epoch: 53, loss: 0.6359883588921453, acc: 0.9808879985789722, prc: 0.15842114663332738, rec: 0.059977009939820136, f1: 0.08701196782421032\n",
            "epoch: 54, loss: 0.6351128253506978, acc: 0.9817001610977234, prc: 0.16892186817983412, rec: 0.05233619582121847, f1: 0.07991327241753136\n",
            "epoch: 55, loss: 0.634241048831418, acc: 0.9822320197383214, prc: 0.17341640706126688, rec: 0.04516870647102576, f1: 0.07166997478676036\n",
            "epoch: 56, loss: 0.6333732939189195, acc: 0.9825338854532555, prc: 0.16914830256104824, rec: 0.03840692406518358, f1: 0.06259987876784041\n",
            "epoch: 57, loss: 0.63250978371379, acc: 0.9828193231020707, prc: 0.1687116564417178, rec: 0.03347082290891879, f1: 0.05585961744625628\n",
            "epoch: 58, loss: 0.6316506806352336, acc: 0.983052396290132, prc: 0.16942626107046593, rec: 0.029751842585705592, f1: 0.05061543770850109\n",
            "epoch: 59, loss: 0.6307960557925574, acc: 0.9832341317715718, prc: 0.16981132075471697, rec: 0.026776658327135033, f1: 0.04625898019975469\n",
            "epoch: 60, loss: 0.6299459145457759, acc: 0.9834107334823495, prc: 0.17304015296367112, rec: 0.024477652309148692, f1: 0.04288845447544577\n",
            "================validation================\n",
            "epoch: 60, loss: 0.6288771614735769, acc: 0.9872518337809977, prc: 0.0967032967032967, rec: 0.01607599561563756, f1: 0.027568922305764413\n",
            "==========================================\n",
            "epoch: 61, loss: 0.6291001948215497, acc: 0.9835873351931274, prc: 0.17849462365591398, rec: 0.02244911758739604, f1: 0.039882275211724424\n",
            "epoch: 62, loss: 0.6282587602993264, acc: 0.9837629101497726, prc: 0.18500307314074985, rec: 0.020352965041584962, f1: 0.03667153996101365\n",
            "epoch: 63, loss: 0.6274214521747913, acc: 0.9839528596642719, prc: 0.1943231441048035, rec: 0.01805395902359862, f1: 0.03303842108519458\n",
            "epoch: 64, loss: 0.6265880713321809, acc: 0.9841387021622415, prc: 0.21172353455818022, rec: 0.016363513422138074, f1: 0.030379111222696455\n",
            "epoch: 65, loss: 0.6257584234726505, acc: 0.9842783407242518, prc: 0.22502628811777076, rec: 0.014470214348502266, f1: 0.02719186785260483\n",
            "epoch: 66, loss: 0.6249323240198351, acc: 0.9843717753503028, prc: 0.23399014778325122, rec: 0.012847386571100142, f1: 0.02435741298634703\n",
            "epoch: 67, loss: 0.6241096330539608, acc: 0.9844395411230431, prc: 0.24793388429752067, rec: 0.012171208330515925, f1: 0.023203351595230425\n",
            "epoch: 68, loss: 0.623290188275841, acc: 0.984499092862724, prc: 0.2652439024390244, rec: 0.011765501386165392, f1: 0.02253156361281968\n",
            "epoch: 69, loss: 0.6224739105294215, acc: 0.9845391362738887, prc: 0.2708688245315162, rec: 0.010751234025289066, f1: 0.020681581685744018\n",
            "epoch: 70, loss: 0.6216607239088621, acc: 0.9845658318813318, prc: 0.274582560296846, rec: 0.010007437960646426, f1: 0.01931106471816284\n",
            "================validation================\n",
            "epoch: 70, loss: 0.6205510543823645, acc: 0.9885742917457266, prc: 0.2077922077922078, rec: 0.005845816587504567, f1: 0.011371712864250177\n",
            "==========================================\n",
            "epoch: 71, loss: 0.6208505775841877, acc: 0.9845904739805101, prc: 0.27422680412371137, rec: 0.0089931705997701, f1: 0.017415215398716776\n",
            "epoch: 72, loss: 0.6200434423182739, acc: 0.984614089325556, prc: 0.27828054298642535, rec: 0.008316992359185881, f1: 0.016151270435296437\n",
            "epoch: 73, loss: 0.6192392813664653, acc: 0.98462846388341, prc: 0.279126213592233, rec: 0.007776049766718507, f1: 0.015130583514242483\n",
            "epoch: 74, loss: 0.6184380824623965, acc: 0.984635651162337, prc: 0.26666666666666666, rec: 0.00676178240584218, f1: 0.013189132155104194\n",
            "epoch: 75, loss: 0.6176397968568005, acc: 0.9846387314247343, prc: 0.2455621301775148, rec: 0.00561227939684901, f1: 0.010973755536457989\n",
            "epoch: 76, loss: 0.6168443961629334, acc: 0.9846459187036612, prc: 0.2347266881028939, rec: 0.004936101156264791, f1: 0.009668874172185432\n",
            "epoch: 77, loss: 0.6160518055411957, acc: 0.9846561862449856, prc: 0.22996515679442509, rec: 0.0044627763878558385, f1: 0.008755638100291854\n",
            "epoch: 78, loss: 0.6152619765272924, acc: 0.9846613200156478, prc: 0.21153846153846154, rec: 0.003718980323213199, f1: 0.007309455777792545\n",
            "epoch: 79, loss: 0.6144748207750196, acc: 0.9846674805404423, prc: 0.20491803278688525, rec: 0.00338089120292109, f1: 0.006652032195835828\n",
            "epoch: 80, loss: 0.6136902589913517, acc: 0.9846777480817666, prc: 0.19545454545454546, rec: 0.0029075664345121375, f1: 0.005729895396095676\n",
            "================validation================\n",
            "epoch: 80, loss: 0.6125363980262883, acc: 0.9886400039427318, prc: 0.10810810810810811, rec: 0.0014614541468761417, f1: 0.002883922134102379\n",
            "==========================================\n",
            "epoch: 81, loss: 0.6129082084177195, acc: 0.9846880156230908, prc: 0.18041237113402062, rec: 0.002366623842044763, f1: 0.004671961556430622\n",
            "epoch: 82, loss: 0.6121285920498851, acc: 0.9846941761478855, prc: 0.16853932584269662, rec: 0.002028534721752654, f1: 0.004008819402685909\n",
            "epoch: 83, loss: 0.6113513280585969, acc: 0.9847023901809449, prc: 0.16049382716049382, rec: 0.0017580634255189669, f1: 0.003478028225536754\n",
            "epoch: 84, loss: 0.6105763494105755, acc: 0.9847116309681367, prc: 0.1564625850340136, rec: 0.0015552099533437014, f1: 0.0030798071772897696\n",
            "epoch: 85, loss: 0.6098035895447625, acc: 0.9847167647387989, prc: 0.14705882352941177, rec: 0.001352356481168436, f1: 0.0026800670016750416\n",
            "epoch: 86, loss: 0.6090330236435542, acc: 0.9847229252635935, prc: 0.1484375, rec: 0.0012847386571100143, f1: 0.0025474291077294364\n",
            "epoch: 87, loss: 0.6082645882870773, acc: 0.9847270322801231, prc: 0.13559322033898305, rec: 0.0010818851849347488, f1: 0.0021466425169383513\n",
            "epoch: 88, loss: 0.6074982743202163, acc: 0.9847249787718583, prc: 0.1, rec: 0.0007437960646426398, f1: 0.0014766091684005637\n",
            "epoch: 89, loss: 0.6067340377192879, acc: 0.9847270322801231, prc: 0.0784313725490196, rec: 0.0005409425924673744, f1: 0.001074474514807602\n",
            "epoch: 90, loss: 0.6059718850456992, acc: 0.9847280590342556, prc: 0.03296703296703297, rec: 0.0002028534721752654, f1: 0.0004032258064516129\n",
            "================validation================\n",
            "epoch: 90, loss: 0.6047699534661629, acc: 0.9886687530289215, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "==========================================\n",
            "epoch: 91, loss: 0.6052117823490835, acc: 0.9847311392966529, prc: 0.011904761904761904, rec: 6.76178240584218e-05, f1: 0.00013447186176292612\n",
            "epoch: 92, loss: 0.6044537260647453, acc: 0.9847331928049178, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 93, loss: 0.6036977108750011, acc: 0.9847393533297123, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 94, loss: 0.6029437083861439, acc: 0.9847578349040961, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 95, loss: 0.602191722675267, acc: 0.9847824770032744, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 96, loss: 0.6014417301764581, acc: 0.984808145856585, prc: 0.0, rec: 0.0, f1: 0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 97, loss: 0.6006937156954304, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 98, loss: 0.5999476672619194, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 99, loss: 0.5992035681687614, acc: 0.9848153331355121, prc: 0.0, rec: 0.0, f1: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0oj-1f5E_Q2"
      },
      "source": [
        "### Show the performance on testing set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_fi-35x20rp",
        "outputId": "38608060-0fad-4941-b8e8-8b7b7ef2dcd5"
      },
      "source": [
        "model_test = simpleNN()\n",
        "model_test.load_state_dict(torch.load('/content/drive/My Drive/fintech-introduction/term-project/simpleNN_s3.pkl'))\n",
        "model_test = model_test.to(device)\n",
        "model_test.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "simpleNN(\n",
              "  (conv): Sequential(\n",
              "    (0): BatchNorm1d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (1): Linear(in_features=23, out_features=10, bias=True)\n",
              "    (2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Sigmoid()\n",
              "    (4): Linear(in_features=10, out_features=5, bias=True)\n",
              "    (5): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): Sigmoid()\n",
              "    (7): Linear(in_features=5, out_features=2, bias=True)\n",
              "    (8): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOWWTarlE-e8"
      },
      "source": [
        "y_pred = model_test(x_test)\n",
        "y_scalar = []\n",
        "for d in y_pred:\n",
        "  if d[0]>d[1]:\n",
        "    y_scalar.append(0)\n",
        "  else:\n",
        "    y_scalar.append(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29ZfpJPUFJPn",
        "outputId": "4150fcd8-4329-4ee4-e24d-03746f3e7fe2"
      },
      "source": [
        "y_target = y_test\n",
        "cm = confusion_matrix(y_target, y_scalar)\n",
        "# row: actually, column: predict, the smaller class will be the target for counting the following indexies\n",
        "print(cm)\n",
        "\n",
        "# these libraries will automatically take the fewer class to evaluate the performance\n",
        "print('accuracy_score: ', accuracy_score(y_target, y_scalar))\n",
        "print(\"precision_score\", precision_score(y_target, y_scalar))\n",
        "print(\"recall_score\",    recall_score(y_target, y_scalar))\n",
        "print(\"f1_score\",        f1_score(y_target, y_scalar))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[299356   2173]\n",
            " [  2360    469]]\n",
            "accuracy_score:  0.9851063550161323\n",
            "precision_score 0.17751703255109766\n",
            "recall_score 0.16578296217744787\n",
            "f1_score 0.1714494607932736\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJJD6w42FJtX",
        "outputId": "7f83e429-079d-4a06-f1c3-9bb36d9918d8"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "simpleNN(\n",
            "  (conv): Sequential(\n",
            "    (0): BatchNorm1d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): Linear(in_features=23, out_features=10, bias=True)\n",
            "    (2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): Sigmoid()\n",
            "    (4): Linear(in_features=10, out_features=5, bias=True)\n",
            "    (5): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): Sigmoid()\n",
            "    (7): Linear(in_features=5, out_features=2, bias=True)\n",
            "    (8): Sigmoid()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3YnLl1V4xgt"
      },
      "source": [
        "# Data Processing scenario 4\n",
        "- Base on scenerio 3\n",
        "- Do normalization on numerical features\n",
        "- Convert catogorical featrues to one hot style\n",
        "- Only about 400000 data in total\n",
        "- 64%(0.8 * 0.8) training data\n",
        "- 16%(0.8 * 0.2) to validate\n",
        "- 20% to test\n",
        "- f1 : 0.2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "Bun1ubnf4y2H",
        "outputId": "931fafde-4202-4438-f64d-ea8671cae067"
      },
      "source": [
        "import pandas as pd\n",
        "with open('/content/drive/My Drive/fintech-introduction/term-project/train_feature_normalization_onehot.csv', 'r') as f:\n",
        "  df = pd.read_csv(f)\n",
        "  # df = df.set_index('txkey')\n",
        "\n",
        "\n",
        "# print(df_X)\n",
        "# print(df_y)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>acqic</th>\n",
              "      <th>bacno</th>\n",
              "      <th>cano</th>\n",
              "      <th>conam</th>\n",
              "      <th>mcc</th>\n",
              "      <th>mchno</th>\n",
              "      <th>scity</th>\n",
              "      <th>contp_0</th>\n",
              "      <th>contp_1</th>\n",
              "      <th>contp_2</th>\n",
              "      <th>contp_3</th>\n",
              "      <th>contp_4</th>\n",
              "      <th>contp_5</th>\n",
              "      <th>contp_6</th>\n",
              "      <th>csmcu_0</th>\n",
              "      <th>csmcu_1</th>\n",
              "      <th>csmcu_2</th>\n",
              "      <th>csmcu_3</th>\n",
              "      <th>csmcu_4</th>\n",
              "      <th>csmcu_5</th>\n",
              "      <th>csmcu_6</th>\n",
              "      <th>csmcu_7</th>\n",
              "      <th>csmcu_9</th>\n",
              "      <th>csmcu_10</th>\n",
              "      <th>csmcu_11</th>\n",
              "      <th>csmcu_12</th>\n",
              "      <th>csmcu_13</th>\n",
              "      <th>csmcu_14</th>\n",
              "      <th>csmcu_15</th>\n",
              "      <th>csmcu_16</th>\n",
              "      <th>csmcu_17</th>\n",
              "      <th>csmcu_18</th>\n",
              "      <th>csmcu_19</th>\n",
              "      <th>csmcu_20</th>\n",
              "      <th>csmcu_21</th>\n",
              "      <th>csmcu_22</th>\n",
              "      <th>csmcu_23</th>\n",
              "      <th>csmcu_24</th>\n",
              "      <th>csmcu_25</th>\n",
              "      <th>...</th>\n",
              "      <th>ss_21</th>\n",
              "      <th>ss_22</th>\n",
              "      <th>ss_23</th>\n",
              "      <th>ss_24</th>\n",
              "      <th>ss_25</th>\n",
              "      <th>ss_26</th>\n",
              "      <th>ss_27</th>\n",
              "      <th>ss_28</th>\n",
              "      <th>ss_29</th>\n",
              "      <th>ss_30</th>\n",
              "      <th>ss_31</th>\n",
              "      <th>ss_32</th>\n",
              "      <th>ss_33</th>\n",
              "      <th>ss_34</th>\n",
              "      <th>ss_35</th>\n",
              "      <th>ss_36</th>\n",
              "      <th>ss_37</th>\n",
              "      <th>ss_38</th>\n",
              "      <th>ss_39</th>\n",
              "      <th>ss_40</th>\n",
              "      <th>ss_41</th>\n",
              "      <th>ss_42</th>\n",
              "      <th>ss_43</th>\n",
              "      <th>ss_44</th>\n",
              "      <th>ss_45</th>\n",
              "      <th>ss_46</th>\n",
              "      <th>ss_47</th>\n",
              "      <th>ss_48</th>\n",
              "      <th>ss_49</th>\n",
              "      <th>ss_50</th>\n",
              "      <th>ss_51</th>\n",
              "      <th>ss_52</th>\n",
              "      <th>ss_53</th>\n",
              "      <th>ss_54</th>\n",
              "      <th>ss_55</th>\n",
              "      <th>ss_56</th>\n",
              "      <th>ss_57</th>\n",
              "      <th>ss_58</th>\n",
              "      <th>ss_59</th>\n",
              "      <th>fraud_ind</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.015972</td>\n",
              "      <td>0.275233</td>\n",
              "      <td>-0.306370</td>\n",
              "      <td>-0.816225</td>\n",
              "      <td>-0.600363</td>\n",
              "      <td>0.738111</td>\n",
              "      <td>0.536349</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.137776</td>\n",
              "      <td>0.483542</td>\n",
              "      <td>0.970861</td>\n",
              "      <td>-0.910290</td>\n",
              "      <td>1.054167</td>\n",
              "      <td>-0.053604</td>\n",
              "      <td>0.921739</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>0.505183</td>\n",
              "      <td>-0.269692</td>\n",
              "      <td>0.266075</td>\n",
              "      <td>0.998239</td>\n",
              "      <td>0.656567</td>\n",
              "      <td>-1.281195</td>\n",
              "      <td>0.536349</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>0.506515</td>\n",
              "      <td>1.151497</td>\n",
              "      <td>1.254999</td>\n",
              "      <td>-0.463005</td>\n",
              "      <td>-0.074504</td>\n",
              "      <td>0.753360</td>\n",
              "      <td>0.536349</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>0.148425</td>\n",
              "      <td>-0.272458</td>\n",
              "      <td>-0.339767</td>\n",
              "      <td>0.566122</td>\n",
              "      <td>-0.266892</td>\n",
              "      <td>-1.192852</td>\n",
              "      <td>0.536349</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456531</th>\n",
              "      <td>1521775</td>\n",
              "      <td>0.506515</td>\n",
              "      <td>-1.239088</td>\n",
              "      <td>0.879340</td>\n",
              "      <td>-0.566652</td>\n",
              "      <td>-0.600363</td>\n",
              "      <td>0.733667</td>\n",
              "      <td>-0.138461</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456532</th>\n",
              "      <td>1521778</td>\n",
              "      <td>0.506515</td>\n",
              "      <td>1.251808</td>\n",
              "      <td>-0.941390</td>\n",
              "      <td>0.134700</td>\n",
              "      <td>-0.651666</td>\n",
              "      <td>0.734737</td>\n",
              "      <td>0.536349</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456533</th>\n",
              "      <td>1521779</td>\n",
              "      <td>0.581061</td>\n",
              "      <td>1.019662</td>\n",
              "      <td>-1.460834</td>\n",
              "      <td>-0.349849</td>\n",
              "      <td>2.041755</td>\n",
              "      <td>0.111695</td>\n",
              "      <td>-2.401805</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456534</th>\n",
              "      <td>1521781</td>\n",
              "      <td>-1.874977</td>\n",
              "      <td>-0.194189</td>\n",
              "      <td>1.676025</td>\n",
              "      <td>0.524985</td>\n",
              "      <td>0.258967</td>\n",
              "      <td>0.412445</td>\n",
              "      <td>0.594436</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456535</th>\n",
              "      <td>1521786</td>\n",
              "      <td>-1.862331</td>\n",
              "      <td>-0.102260</td>\n",
              "      <td>0.699285</td>\n",
              "      <td>-0.652525</td>\n",
              "      <td>-0.048853</td>\n",
              "      <td>-0.401039</td>\n",
              "      <td>-1.265840</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>456536 rows × 388 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Unnamed: 0     acqic     bacno  ...  ss_58  ss_59  fraud_ind\n",
              "0                1  0.015972  0.275233  ...    0.0    0.0          0\n",
              "1                2  0.137776  0.483542  ...    0.0    0.0          0\n",
              "2                5  0.505183 -0.269692  ...    0.0    0.0          0\n",
              "3                6  0.506515  1.151497  ...    0.0    0.0          0\n",
              "4                7  0.148425 -0.272458  ...    0.0    0.0          0\n",
              "...            ...       ...       ...  ...    ...    ...        ...\n",
              "456531     1521775  0.506515 -1.239088  ...    0.0    0.0          0\n",
              "456532     1521778  0.506515  1.251808  ...    0.0    0.0          0\n",
              "456533     1521779  0.581061  1.019662  ...    0.0    0.0          0\n",
              "456534     1521781 -1.874977 -0.194189  ...    0.0    0.0          0\n",
              "456535     1521786 -1.862331 -0.102260  ...    0.0    0.0          0\n",
              "\n",
              "[456536 rows x 388 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "E5eZHFRk4-TH",
        "outputId": "a464dcb1-d58b-4437-db00-741175d816e5"
      },
      "source": [
        "df_y = df['fraud_ind']\n",
        "df_x = df.drop(['fraud_ind', 'Unnamed: 0'], 1)\n",
        "df_x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>acqic</th>\n",
              "      <th>bacno</th>\n",
              "      <th>cano</th>\n",
              "      <th>conam</th>\n",
              "      <th>mcc</th>\n",
              "      <th>mchno</th>\n",
              "      <th>scity</th>\n",
              "      <th>contp_0</th>\n",
              "      <th>contp_1</th>\n",
              "      <th>contp_2</th>\n",
              "      <th>contp_3</th>\n",
              "      <th>contp_4</th>\n",
              "      <th>contp_5</th>\n",
              "      <th>contp_6</th>\n",
              "      <th>csmcu_0</th>\n",
              "      <th>csmcu_1</th>\n",
              "      <th>csmcu_2</th>\n",
              "      <th>csmcu_3</th>\n",
              "      <th>csmcu_4</th>\n",
              "      <th>csmcu_5</th>\n",
              "      <th>csmcu_6</th>\n",
              "      <th>csmcu_7</th>\n",
              "      <th>csmcu_9</th>\n",
              "      <th>csmcu_10</th>\n",
              "      <th>csmcu_11</th>\n",
              "      <th>csmcu_12</th>\n",
              "      <th>csmcu_13</th>\n",
              "      <th>csmcu_14</th>\n",
              "      <th>csmcu_15</th>\n",
              "      <th>csmcu_16</th>\n",
              "      <th>csmcu_17</th>\n",
              "      <th>csmcu_18</th>\n",
              "      <th>csmcu_19</th>\n",
              "      <th>csmcu_20</th>\n",
              "      <th>csmcu_21</th>\n",
              "      <th>csmcu_22</th>\n",
              "      <th>csmcu_23</th>\n",
              "      <th>csmcu_24</th>\n",
              "      <th>csmcu_25</th>\n",
              "      <th>csmcu_26</th>\n",
              "      <th>...</th>\n",
              "      <th>ss_20</th>\n",
              "      <th>ss_21</th>\n",
              "      <th>ss_22</th>\n",
              "      <th>ss_23</th>\n",
              "      <th>ss_24</th>\n",
              "      <th>ss_25</th>\n",
              "      <th>ss_26</th>\n",
              "      <th>ss_27</th>\n",
              "      <th>ss_28</th>\n",
              "      <th>ss_29</th>\n",
              "      <th>ss_30</th>\n",
              "      <th>ss_31</th>\n",
              "      <th>ss_32</th>\n",
              "      <th>ss_33</th>\n",
              "      <th>ss_34</th>\n",
              "      <th>ss_35</th>\n",
              "      <th>ss_36</th>\n",
              "      <th>ss_37</th>\n",
              "      <th>ss_38</th>\n",
              "      <th>ss_39</th>\n",
              "      <th>ss_40</th>\n",
              "      <th>ss_41</th>\n",
              "      <th>ss_42</th>\n",
              "      <th>ss_43</th>\n",
              "      <th>ss_44</th>\n",
              "      <th>ss_45</th>\n",
              "      <th>ss_46</th>\n",
              "      <th>ss_47</th>\n",
              "      <th>ss_48</th>\n",
              "      <th>ss_49</th>\n",
              "      <th>ss_50</th>\n",
              "      <th>ss_51</th>\n",
              "      <th>ss_52</th>\n",
              "      <th>ss_53</th>\n",
              "      <th>ss_54</th>\n",
              "      <th>ss_55</th>\n",
              "      <th>ss_56</th>\n",
              "      <th>ss_57</th>\n",
              "      <th>ss_58</th>\n",
              "      <th>ss_59</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.015972</td>\n",
              "      <td>0.275233</td>\n",
              "      <td>-0.306370</td>\n",
              "      <td>-0.816225</td>\n",
              "      <td>-0.600363</td>\n",
              "      <td>0.738111</td>\n",
              "      <td>0.536349</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.137776</td>\n",
              "      <td>0.483542</td>\n",
              "      <td>0.970861</td>\n",
              "      <td>-0.910290</td>\n",
              "      <td>1.054167</td>\n",
              "      <td>-0.053604</td>\n",
              "      <td>0.921739</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.505183</td>\n",
              "      <td>-0.269692</td>\n",
              "      <td>0.266075</td>\n",
              "      <td>0.998239</td>\n",
              "      <td>0.656567</td>\n",
              "      <td>-1.281195</td>\n",
              "      <td>0.536349</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.506515</td>\n",
              "      <td>1.151497</td>\n",
              "      <td>1.254999</td>\n",
              "      <td>-0.463005</td>\n",
              "      <td>-0.074504</td>\n",
              "      <td>0.753360</td>\n",
              "      <td>0.536349</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.148425</td>\n",
              "      <td>-0.272458</td>\n",
              "      <td>-0.339767</td>\n",
              "      <td>0.566122</td>\n",
              "      <td>-0.266892</td>\n",
              "      <td>-1.192852</td>\n",
              "      <td>0.536349</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456531</th>\n",
              "      <td>0.506515</td>\n",
              "      <td>-1.239088</td>\n",
              "      <td>0.879340</td>\n",
              "      <td>-0.566652</td>\n",
              "      <td>-0.600363</td>\n",
              "      <td>0.733667</td>\n",
              "      <td>-0.138461</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456532</th>\n",
              "      <td>0.506515</td>\n",
              "      <td>1.251808</td>\n",
              "      <td>-0.941390</td>\n",
              "      <td>0.134700</td>\n",
              "      <td>-0.651666</td>\n",
              "      <td>0.734737</td>\n",
              "      <td>0.536349</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456533</th>\n",
              "      <td>0.581061</td>\n",
              "      <td>1.019662</td>\n",
              "      <td>-1.460834</td>\n",
              "      <td>-0.349849</td>\n",
              "      <td>2.041755</td>\n",
              "      <td>0.111695</td>\n",
              "      <td>-2.401805</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456534</th>\n",
              "      <td>-1.874977</td>\n",
              "      <td>-0.194189</td>\n",
              "      <td>1.676025</td>\n",
              "      <td>0.524985</td>\n",
              "      <td>0.258967</td>\n",
              "      <td>0.412445</td>\n",
              "      <td>0.594436</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456535</th>\n",
              "      <td>-1.862331</td>\n",
              "      <td>-0.102260</td>\n",
              "      <td>0.699285</td>\n",
              "      <td>-0.652525</td>\n",
              "      <td>-0.048853</td>\n",
              "      <td>-0.401039</td>\n",
              "      <td>-1.265840</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>456536 rows × 386 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           acqic     bacno      cano     conam  ...  ss_56  ss_57  ss_58  ss_59\n",
              "0       0.015972  0.275233 -0.306370 -0.816225  ...    0.0    0.0    0.0    0.0\n",
              "1       0.137776  0.483542  0.970861 -0.910290  ...    0.0    0.0    0.0    0.0\n",
              "2       0.505183 -0.269692  0.266075  0.998239  ...    0.0    0.0    0.0    0.0\n",
              "3       0.506515  1.151497  1.254999 -0.463005  ...    0.0    0.0    0.0    0.0\n",
              "4       0.148425 -0.272458 -0.339767  0.566122  ...    0.0    0.0    0.0    0.0\n",
              "...          ...       ...       ...       ...  ...    ...    ...    ...    ...\n",
              "456531  0.506515 -1.239088  0.879340 -0.566652  ...    0.0    0.0    0.0    0.0\n",
              "456532  0.506515  1.251808 -0.941390  0.134700  ...    0.0    0.0    0.0    0.0\n",
              "456533  0.581061  1.019662 -1.460834 -0.349849  ...    0.0    0.0    0.0    0.0\n",
              "456534 -1.874977 -0.194189  1.676025  0.524985  ...    0.0    0.0    0.0    0.0\n",
              "456535 -1.862331 -0.102260  0.699285 -0.652525  ...    0.0    0.0    0.0    0.0\n",
              "\n",
              "[456536 rows x 386 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0p1AasDa5Dko",
        "outputId": "7925f585-b53e-447a-8c04-451637d99bab"
      },
      "source": [
        "# split train+val and test\n",
        "df_x_data, df_x_test = train_test_split(df_x, test_size=0.2, shuffle=False)\n",
        "df_y_data = df_y.loc[df_x_data.index]\n",
        "df_y_test = df_y.loc[df_x_test.index]\n",
        "\n",
        "# print(df_x_data)\n",
        "# print(df_x_test)\n",
        "# print(df_y_data)\n",
        "# print(df_y_test)\n",
        "\n",
        "#split train and val\n",
        "df_x_train, df_x_val = train_test_split(df_x_data, test_size=0.2, shuffle=False)\n",
        "df_y_train = df_y_data.loc[df_x_train.index]\n",
        "df_y_val = df_y_data.loc[df_x_val.index]\n",
        "\n",
        "\n",
        "print('df_x_train:')\n",
        "print(df_x_train)\n",
        "print('df_x_val:')\n",
        "print(df_x_val)\n",
        "print('df_x_test:')\n",
        "print(df_x_test)\n",
        "print('df_y_train:')\n",
        "print(df_y_train)\n",
        "print('df_y_val:')\n",
        "print(df_y_val)\n",
        "print('df_y_test:')\n",
        "print(df_y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "df_x_train:\n",
            "           acqic     bacno      cano     conam  ...  ss_56  ss_57  ss_58  ss_59\n",
            "0       0.015972  0.275233 -0.306370 -0.816225  ...    0.0    0.0    0.0    0.0\n",
            "1       0.137776  0.483542  0.970861 -0.910290  ...    0.0    0.0    0.0    0.0\n",
            "2       0.505183 -0.269692  0.266075  0.998239  ...    0.0    0.0    0.0    0.0\n",
            "3       0.506515  1.151497  1.254999 -0.463005  ...    0.0    0.0    0.0    0.0\n",
            "4       0.148425 -0.272458 -0.339767  0.566122  ...    0.0    0.0    0.0    0.0\n",
            "...          ...       ...       ...       ...  ...    ...    ...    ...    ...\n",
            "292177  0.471238  0.803964 -0.201122 -0.217975  ...    0.0    0.0    0.0    0.0\n",
            "292178 -0.021966 -1.333889 -0.129599  0.397182  ...    0.0    0.0    0.0    0.0\n",
            "292179  0.015972 -1.581785 -1.297132 -0.719554  ...    0.0    0.0    0.0    0.0\n",
            "292180  0.560428  1.225965  0.897187  0.087879  ...    0.0    0.0    0.0    0.0\n",
            "292181 -3.998885  0.123024  1.271188 -0.469459  ...    0.0    0.0    0.0    0.0\n",
            "\n",
            "[292182 rows x 386 columns]\n",
            "df_x_val:\n",
            "           acqic     bacno      cano     conam  ...  ss_56  ss_57  ss_58  ss_59\n",
            "292182  0.410669  1.251048  1.336291 -1.136924  ...    0.0    0.0    0.0    0.0\n",
            "292183  0.506515 -1.222471 -0.336631  0.023207  ...    0.0    0.0    0.0    0.0\n",
            "292184  0.581061  0.613159  0.159202 -0.349849  ...    0.0    0.0    0.0    0.0\n",
            "292185  0.017969  1.321885 -0.563219  0.193736  ...    0.0    0.0    0.0    0.0\n",
            "292186  0.015972  1.372199 -0.197838 -0.306851  ...    0.0    0.0    0.0    0.0\n",
            "...          ...       ...       ...       ...  ...    ...    ...    ...    ...\n",
            "365223  0.553106 -1.291640  1.261681  1.411339  ...    0.0    0.0    0.0    0.0\n",
            "365224  0.581061  1.455725 -0.890982 -0.349849  ...    0.0    0.0    0.0    0.0\n",
            "365225  0.553106 -1.723754  0.040325 -0.794826  ...    0.0    0.0    0.0    0.0\n",
            "365226  0.549778  0.556321  0.873576  0.052080  ...    0.0    0.0    0.0    0.0\n",
            "365227 -1.770479 -1.391550 -1.211144 -1.368499  ...    0.0    0.0    0.0    0.0\n",
            "\n",
            "[73046 rows x 386 columns]\n",
            "df_x_test:\n",
            "           acqic     bacno      cano     conam  ...  ss_56  ss_57  ss_58  ss_59\n",
            "365228  0.505183 -1.111455  0.353230  3.235783  ...    0.0    0.0    0.0    0.0\n",
            "365229 -0.021966  0.284629  0.493435  0.738437  ...    0.0    0.0    0.0    0.0\n",
            "365230  0.445280  0.143906  1.203426 -0.109710  ...    0.0    0.0    0.0    0.0\n",
            "365231 -1.770479  1.277862 -0.727347 -1.088862  ...    0.0    0.0    0.0    0.0\n",
            "365232  0.513170  0.026703  1.618179 -0.470775  ...    0.0    0.0    0.0    0.0\n",
            "...          ...       ...       ...       ...  ...    ...    ...    ...    ...\n",
            "456531  0.506515 -1.239088  0.879340 -0.566652  ...    0.0    0.0    0.0    0.0\n",
            "456532  0.506515  1.251808 -0.941390  0.134700  ...    0.0    0.0    0.0    0.0\n",
            "456533  0.581061  1.019662 -1.460834 -0.349849  ...    0.0    0.0    0.0    0.0\n",
            "456534 -1.874977 -0.194189  1.676025  0.524985  ...    0.0    0.0    0.0    0.0\n",
            "456535 -1.862331 -0.102260  0.699285 -0.652525  ...    0.0    0.0    0.0    0.0\n",
            "\n",
            "[91308 rows x 386 columns]\n",
            "df_y_train:\n",
            "0         0\n",
            "1         0\n",
            "2         0\n",
            "3         0\n",
            "4         0\n",
            "         ..\n",
            "292177    0\n",
            "292178    0\n",
            "292179    0\n",
            "292180    0\n",
            "292181    0\n",
            "Name: fraud_ind, Length: 292182, dtype: int64\n",
            "df_y_val:\n",
            "292182    0\n",
            "292183    0\n",
            "292184    0\n",
            "292185    0\n",
            "292186    0\n",
            "         ..\n",
            "365223    0\n",
            "365224    0\n",
            "365225    0\n",
            "365226    0\n",
            "365227    0\n",
            "Name: fraud_ind, Length: 73046, dtype: int64\n",
            "df_y_test:\n",
            "365228    0\n",
            "365229    0\n",
            "365230    0\n",
            "365231    0\n",
            "365232    0\n",
            "         ..\n",
            "456531    0\n",
            "456532    0\n",
            "456533    0\n",
            "456534    0\n",
            "456535    0\n",
            "Name: fraud_ind, Length: 91308, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-PtWfG35qRm"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import math\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "lr = 1e-2\n",
        "batch_size = 292182\n",
        "batch_num = math.ceil(df_x_train.shape[0] / batch_size)\n",
        "max_epoch = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zv3C3Ik5tBC"
      },
      "source": [
        "x_train = torch.from_numpy(df_x_train.values).to(device)\n",
        "y_train = torch.from_numpy(df_y_train.values).to(device)\n",
        "loader = DataLoader(TensorDataset(x_train, y_train), batch_size=batch_size, shuffle=True)\n",
        "\n",
        "x_val = torch.from_numpy(df_x_val.values).to(device)\n",
        "y_val = torch.from_numpy(df_y_val.values).to(device)\n",
        "\n",
        "x_test = torch.from_numpy(df_x_test.values).to(device)\n",
        "y_test = torch.from_numpy(df_y_test.values).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OBW1ywx5-S0"
      },
      "source": [
        "n = x_train.shape[1]\n",
        "class simpleNN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(simpleNN, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Linear(n, 10),\n",
        "            nn.BatchNorm1d(10),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(10,5),\n",
        "            nn.BatchNorm1d(5),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(5,2),\n",
        "            # nn.BatchNorm1d(2),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.y_pred = self.conv(x.float())\n",
        "        return self.y_pred\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss().to(device)\n",
        "model = simpleNN()\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yvl1bmQ26Ffm"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKQTtmfj6AQX",
        "outputId": "e56de9c2-bff4-4100-e775-3f54dd9f65e8"
      },
      "source": [
        "model.train()\n",
        "val_f1_max = 0\n",
        "for epoch in range(max_epoch):\n",
        "  e_loss = 0\n",
        "  e_acc = 0\n",
        "  e_prc = 0\n",
        "  e_rec = 0\n",
        "  e_f1 = 0\n",
        "\n",
        "  for x_batch, y_batch in loader:\n",
        "    current_size = y_batch.shape[0]\n",
        "    optimizer.zero_grad()\n",
        "    y_pred = model(x_batch)\n",
        "    y_scalar = []\n",
        "    for d in y_pred:\n",
        "      if d[0]>d[1]:\n",
        "        y_scalar.append(0)\n",
        "      else:\n",
        "        y_scalar.append(1)\n",
        "    \n",
        "    loss = loss_func(y_pred.double(), y_batch.flatten().long()).to(device)\n",
        "    e_loss += loss.item()\n",
        "    # loss = loss.float()\n",
        "\n",
        "    e_acc += accuracy_score(y_batch, y_scalar)\n",
        "    e_prc += precision_score(y_batch, y_scalar)\n",
        "    e_rec += recall_score(y_batch, y_scalar)\n",
        "    e_f1 += f1_score(y_batch, y_scalar)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  \n",
        "  e_acc = (e_acc / batch_num)\n",
        "  e_loss = (e_loss / batch_num)\n",
        "  e_prc = (e_prc / batch_num)\n",
        "  e_rec = (e_rec / batch_num)\n",
        "  e_f1 = (e_f1 / batch_num)\n",
        "  print('epoch: {}, loss: {}, acc: {}, prc: {}, rec: {}, f1: {}'.format(epoch, e_loss, e_acc, e_prc, e_rec, e_f1))\n",
        "\n",
        "  if epoch%10 == 0:\n",
        "    y_pred = model(x_val)\n",
        "    y_scalar = []\n",
        "    for d in y_pred:\n",
        "      if d[0]>d[1]:\n",
        "        y_scalar.append(0)\n",
        "      else:\n",
        "        y_scalar.append(1)\n",
        "    \n",
        "\n",
        "    val_loss = loss_func(y_pred.double(), y_val.flatten().long()).to(device)\n",
        "    val_acc = accuracy_score(y_val, y_scalar)\n",
        "    val_prc = precision_score(y_val, y_scalar)\n",
        "    val_rec = recall_score(y_val, y_scalar)\n",
        "    val_f1 = f1_score(y_val, y_scalar)\n",
        "    print(\"================validation================\")\n",
        "    print('epoch: {}, loss: {}, acc: {}, prc: {}, rec: {}, f1: {}'.format(epoch, val_loss, val_acc, val_prc, val_rec, val_f1))\n",
        "    if val_f1 > val_f1_max:\n",
        "        val_f1_max = val_f1\n",
        "        torch.save(model.state_dict(), '/content/drive/My Drive/fintech-introduction/term-project/simpleNN_s4.pkl')\n",
        "        print('update_file')\n",
        "    print('==========================================')\n",
        "\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, loss: 0.7009114580958916, acc: 0.33688591357441594, prc: 0.01515950772571534, rec: 0.6707455245864491, f1: 0.029648920719186657\n",
            "================validation================\n",
            "epoch: 0, loss: 0.6915941647137582, acc: 0.5559921145579498, prc: 0.0250210767192581, rec: 0.9411098527746319, f1: 0.04874615046194457\n",
            "update_file\n",
            "==========================================\n",
            "epoch: 1, loss: 0.6914883152875058, acc: 0.5575600139638992, prc: 0.03128519302671291, rec: 0.9442556084296397, f1: 0.0605637794588938\n",
            "epoch: 2, loss: 0.6826695188367808, acc: 0.7389503802424516, prc: 0.047161131766336885, rec: 0.8479492408792205, f1: 0.08935265885049787\n",
            "epoch: 3, loss: 0.6740386319996249, acc: 0.8624658603199375, prc: 0.06957212302064783, rec: 0.6551099025606164, f1: 0.12578588987752082\n",
            "epoch: 4, loss: 0.6655740780457919, acc: 0.9263096289299135, prc: 0.10172173103769196, rec: 0.4953546340358033, f1: 0.16878353858626416\n",
            "epoch: 5, loss: 0.657270768225132, acc: 0.9589228631469426, prc: 0.14959830085880507, rec: 0.36709721278042146, f1: 0.2125705288019945\n",
            "epoch: 6, loss: 0.6490825956257611, acc: 0.9769527212490845, prc: 0.237976969970648, rec: 0.23883979152503965, f1: 0.23840760009047726\n",
            "epoch: 7, loss: 0.6409625611586872, acc: 0.9840647267798838, prc: 0.39781328847771236, rec: 0.10718332200317245, f1: 0.1688682613352374\n",
            "epoch: 8, loss: 0.6328974873610284, acc: 0.9848861326159722, prc: 0.0, rec: 0.0, f1: 0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 9, loss: 0.6248993523379407, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 10, loss: 0.6169920898652481, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "================validation================\n",
            "epoch: 10, loss: 0.6089821764040474, acc: 0.987911726857049, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "==========================================\n",
            "epoch: 11, loss: 0.6092029063309392, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 12, loss: 0.601548817281252, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 13, loss: 0.5940248557349813, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 14, loss: 0.5866125469563257, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 15, loss: 0.5793034422780157, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 16, loss: 0.5721089992125988, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 17, loss: 0.5650515609419641, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 18, loss: 0.5581476224303261, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 19, loss: 0.55139806585372, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 20, loss: 0.5447935882787625, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "================validation================\n",
            "epoch: 20, loss: 0.5376323715780792, acc: 0.987911726857049, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "==========================================\n",
            "epoch: 21, loss: 0.5383261770640558, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 22, loss: 0.5319946726423906, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 23, loss: 0.5258028177834841, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 24, loss: 0.5197543289943136, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 25, loss: 0.5138488155923963, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 26, loss: 0.5080832928193256, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 27, loss: 0.502457005186961, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 28, loss: 0.4969738279056485, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 29, loss: 0.49163863977198086, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 30, loss: 0.4864533317478112, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "================validation================\n",
            "epoch: 30, loss: 0.48051477149401195, acc: 0.987911726857049, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "==========================================\n",
            "epoch: 31, loss: 0.4814169112783168, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 32, loss: 0.47652571654011616, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 33, loss: 0.4717750969230936, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 34, loss: 0.4671622599189354, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 35, loss: 0.4626884157343137, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 36, loss: 0.45835360801655634, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 37, loss: 0.45415221050628013, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 38, loss: 0.45007664073886744, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 39, loss: 0.4461236159651904, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 40, loss: 0.4422951564039414, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "================validation================\n",
            "epoch: 40, loss: 0.4374656624510848, acc: 0.987911726857049, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "==========================================\n",
            "epoch: 41, loss: 0.43859669898708054, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 42, loss: 0.4350364643206413, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 43, loss: 0.43162163827648303, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 44, loss: 0.42834786780290374, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 45, loss: 0.4251990257475942, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 46, loss: 0.4221660651969373, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 47, loss: 0.4192507571478617, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 48, loss: 0.4164494858214414, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 49, loss: 0.4137513720713806, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 50, loss: 0.4111489728531021, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "================validation================\n",
            "epoch: 50, loss: 0.4073090122192012, acc: 0.987911726857049, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "==========================================\n",
            "epoch: 51, loss: 0.40864010743517165, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 52, loss: 0.40622495848262274, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 53, loss: 0.40390452869812216, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 54, loss: 0.4016770534836065, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 55, loss: 0.3995374112185599, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 56, loss: 0.3974814632851483, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 57, loss: 0.39550641583515844, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 58, loss: 0.3936081852814508, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 59, loss: 0.391782461604353, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 60, loss: 0.39002605220652337, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "================validation================\n",
            "epoch: 60, loss: 0.38682756172135463, acc: 0.987911726857049, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "==========================================\n",
            "epoch: 61, loss: 0.388335790609678, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 62, loss: 0.38670805961267846, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 63, loss: 0.3851394188957046, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 64, loss: 0.3836270704408427, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 65, loss: 0.3821688187725525, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 66, loss: 0.3807628505122734, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 67, loss: 0.37940762214409773, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 68, loss: 0.37810176316139904, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 69, loss: 0.3768439161584521, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 70, loss: 0.3756322249724588, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "================validation================\n",
            "epoch: 70, loss: 0.37281686480641796, acc: 0.987911726857049, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "==========================================\n",
            "epoch: 71, loss: 0.3744642591814604, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 72, loss: 0.37333758214670093, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 73, loss: 0.3722502493862567, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 74, loss: 0.37120087229844456, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 75, loss: 0.3701883091343845, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 76, loss: 0.3692111288875525, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 77, loss: 0.3682677157292541, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 78, loss: 0.36735672940144054, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 79, loss: 0.3664768445097512, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 80, loss: 0.36562658543310195, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "================validation================\n",
            "epoch: 80, loss: 0.36303871912115687, acc: 0.987911726857049, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "==========================================\n",
            "epoch: 81, loss: 0.36480468952400263, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 82, loss: 0.3640101877855175, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 83, loss: 0.3632420473255132, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 84, loss: 0.3624989933628876, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 85, loss: 0.36177958280661865, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 86, loss: 0.3610824535909904, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 87, loss: 0.36040654199952976, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 88, loss: 0.3597509602842877, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 89, loss: 0.35911490729834994, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 90, loss: 0.3584976358043165, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "================validation================\n",
            "epoch: 90, loss: 0.3560529489811462, acc: 0.987911726857049, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "==========================================\n",
            "epoch: 91, loss: 0.3578984811168455, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 92, loss: 0.35731681410442634, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 93, loss: 0.3567519827387897, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 94, loss: 0.35620339492584685, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 95, loss: 0.3556705801062801, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 96, loss: 0.355153057889709, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 97, loss: 0.3546503006341478, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 98, loss: 0.3541617657883056, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n",
            "epoch: 99, loss: 0.3536869160410076, acc: 0.9848964001889233, prc: 0.0, rec: 0.0, f1: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ub-Sy9U76YUO"
      },
      "source": [
        "### Show the performance on testing set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVxtdYAs6Xil",
        "outputId": "ba559038-1a03-4a3b-c7ff-a70a3302267b"
      },
      "source": [
        "model_test = simpleNN()\n",
        "model_test.load_state_dict(torch.load('/content/drive/My Drive/fintech-introduction/term-project/simpleNN_s4.pkl'))\n",
        "model_test = model_test.to(device)\n",
        "model_test.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "simpleNN(\n",
              "  (conv): Sequential(\n",
              "    (0): BatchNorm1d(386, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (1): Linear(in_features=386, out_features=10, bias=True)\n",
              "    (2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Sigmoid()\n",
              "    (4): Linear(in_features=10, out_features=5, bias=True)\n",
              "    (5): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): Sigmoid()\n",
              "    (7): Linear(in_features=5, out_features=2, bias=True)\n",
              "    (8): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRuKim9z6esF"
      },
      "source": [
        "y_pred = model_test(x_test)\n",
        "y_scalar = []\n",
        "for d in y_pred:\n",
        "  if d[0]>d[1]:\n",
        "    y_scalar.append(0)\n",
        "  else:\n",
        "    y_scalar.append(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59xlgwRU6hLK",
        "outputId": "e514cc65-959b-4fa9-a116-8aabbfa04bc2"
      },
      "source": [
        "y_target = y_test\n",
        "cm = confusion_matrix(y_target, y_scalar)\n",
        "# row: actually, column: predict, the smaller class will be the target for counting the following indexies\n",
        "print(cm)\n",
        "\n",
        "# these libraries will automatically take the fewer class to evaluate the performance\n",
        "print('accuracy_score: ', accuracy_score(y_target, y_scalar))\n",
        "print(\"precision_score\", precision_score(y_target, y_scalar))\n",
        "print(\"recall_score\",    recall_score(y_target, y_scalar))\n",
        "print(\"f1_score\",        f1_score(y_target, y_scalar))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[90018   455]\n",
            " [  688   147]]\n",
            "accuracy_score:  0.9874819292942568\n",
            "precision_score 0.2441860465116279\n",
            "recall_score 0.17604790419161676\n",
            "f1_score 0.2045929018789144\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNEUyChT6hna",
        "outputId": "0f3eb64b-a53d-43a9-d738-0b7b13bcb98a"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "simpleNN(\n",
            "  (conv): Sequential(\n",
            "    (0): BatchNorm1d(386, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): Linear(in_features=386, out_features=10, bias=True)\n",
            "    (2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): Sigmoid()\n",
            "    (4): Linear(in_features=10, out_features=5, bias=True)\n",
            "    (5): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): Sigmoid()\n",
            "    (7): Linear(in_features=5, out_features=2, bias=True)\n",
            "    (8): Sigmoid()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}